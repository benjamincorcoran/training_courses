{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d7648f5-c772-48c4-b00a-9d210d38f1ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Introduction to Data Engineering \n",
    "<br><br>\n",
    "\n",
    "**ONS / NISR** <br>\n",
    "2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9393bdd0-f620-4e90-b063-1f3873cc2642",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## What does a data engineer do?\n",
    "\n",
    "Data engineers are responsible for designing, developing, and maintaining the data platform, which includes the data infrastructure, data applications, data warehouse and data pipelines.\n",
    "\n",
    "In a big company, data engineers are usually divided into different groups that work with specific part of the data platform. <br><br>\n",
    "\n",
    "<center><img src=\"./imgs/engineer_stack.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed2fcc9-1a07-4232-ac65-db24814ef309",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Data warehouses\n",
    "\n",
    "A **data warehouse** is a data storage system filled with data from various sources and is used for data analysis. It is different from a traditional **database**. A traditional **database** is great for updating and retrieving values, but is inefficient for analytical and data science purposes. \n",
    "\n",
    "<center><img src=\"./imgs/datawarehouse.png\" width=300px height=300px style=\"\"><br><caption><em>A visual respresentation of a data warehouse</em></caption></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e75b7dd-7bfb-4977-9565-fd0db7bde1a8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### What is a data warehouse? \n",
    "\n",
    "A data warehouse is a data storage system filled with data from **various sources** and is used for data analysis. \n",
    "\n",
    "Most data in the real world is stored in different transactional systems (or even worse, as text files!). Transactional data isn't very efficient for use in analysis and data science. \n",
    "\n",
    "The main reason for building a data warehouse is to store **all** types of data in **optimized formats** in a centralized place so that data scientists can analyse all the data altogether. \n",
    "\n",
    "<center>A data warehouse makes <b>many</b> different datasets available to data scientists in a format that is <b>optimised</b> for analytical work.</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb81caf-b595-4eb6-8814-61424fa78d46",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### What technologies do data warehouses use? \n",
    "\n",
    "There are many databases that serve well as a data warehouse, such as Apache Hive, BigQuery, and Redshift.   \n",
    "\n",
    "<table style=\"text-align:center\">\n",
    "<tr><td>\n",
    "<img src=\"./imgs/hivelogo.png\" width=150></td><td>\n",
    "<img src=\"./imgs/bigquerylogo.png\" width=300></td><td>\n",
    "<img src=\"./imgs/redshiftlogo.png\" width=250></td></tr></table> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba10f6-01b6-4d7f-8a79-62beef2e54b6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Data Lakes\n",
    "\n",
    "In big data contexts, where we're talking about massive volumes of rapidly changing information streams data warehouses usually aren't able to accommodate. For example live tweets from every person in Rwanda.  \n",
    "\n",
    "A data lake is a solution to store all sorts of raw and semi-structured data in a big...lake. \n",
    "\n",
    "It is a vast pool for saving data in its native, unprocessed form. A data lake stands out for its high agility as it isn’t limited to a warehouse’s fixed configuration.\n",
    "\n",
    "Data lakes are relatively new and as such their security models are not quite as mature as data warehouses but they can be incredibly valuable for data scientists. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c3a0bc-d4d7-4a0e-990b-cd8897029dca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### What technologies do data lakes use? \n",
    "\n",
    "Most big cloud providers now offer data lake technology such as Amazons' S3 service and Microsoft's blob storage. \n",
    "\n",
    "<table style=\"text-align:center\">\n",
    "    <tr><td><img src=\"./imgs/hadoop.png\" width=250></td><td>\n",
    "<img src=\"./imgs/s3logo.png\" width=250></td><td>\n",
    "<img src=\"./imgs/blobstoragelogo.png\" width=300></td></tr></table> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ecfc5f-8d1b-416e-81fd-5ea7f915e567",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Compute Resources\n",
    "\n",
    "As the data warehouse doesn't do anything by itself we need a **compute** layer to apply algorithms to the data in our warehouse. \n",
    "\n",
    "The difficulty is that algorithms come in all different shapes and sizes meaning our compute layer need to be flexible to the needs of our data scientists. \n",
    "\n",
    "<center><img src=\"./imgs/compute.png\" width=300px height=300px style=\"margin: -15px\"><br><caption><em>A visual representation of the compute layer</em></caption></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50499386-e446-42b9-8211-20054a207165",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### A history of two data science compute layers\n",
    "\n",
    "Its important to remember that just like data science, data infrastructure is an iterative process that **will** need to expand as the needs of the business grow. <br><br>\n",
    "\n",
    "<table style=\"font-size:20px\">\n",
    "    <tr><th>ONS Data Science Campus</th><th>OfS Data, Foresight & Analysis</th><tr>\n",
    "    <tr><td>No infrastructure</td><td>No infrastructure</td></tr>\n",
    "    <tr><td>Working with local data on average laptops</td><td>Working with local data on average laptops</td></tr>\n",
    "    <tr><td>Working with local data on better laptops</td><td>Working with local data on better laptops</td></tr>\n",
    "    <tr><td>On premise DAP</td><td>On premise SAS severs</td></tr>\n",
    "    <tr><td>Cloud Software / Data</td><td>Cloud data and compute with Azure Databricks</td></tr>\n",
    "    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bb6f3e-e41b-4b7a-855c-cdc07e530133",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Job Scheduler / Pipelines\n",
    "\n",
    "New data is being generated all the time, similarly data science projects will want to be able to take advantage of the newest data whenever possible. We want to refresh our data sources and data science results with a regular cadence. \n",
    "\n",
    "The scheduler layer keeps all these processes ticking along automatically. \n",
    "\n",
    "<center><img src=\"./imgs/jobschedule.png\" width=300px height=300px style=\"margin: -20px\"><br><caption><em>A visual representation of the scheduler layer</em></caption></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3767959f-9554-4336-9b09-f38ceb9e7177",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### What is a data pipeline?\n",
    "\n",
    "A data pipeline is a series of data processes that extract, process and load data between different systems. \n",
    "\n",
    "There are two types of data pipeline:\n",
    "\n",
    "<table style=\"font-size:20px\"><tr><td>Batch-driven</td><td>Real-time</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec9541e-3f69-46ce-aecd-2e1f6792203b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Batch-driven pipelines\n",
    "\n",
    "Batch data pipelines only process data at a certain frequency, i.e. once a day. They usually process a large **batch** of historical data all at once, usually taking a long time to finish. \n",
    "\n",
    "For example a batch-driven pipeline could download the previous day's data from an API at 12 AM every day, transform the data and then load it into the data warehouse. \n",
    "\n",
    "<table style=\"text-align:center\">\n",
    "<tr><td>\n",
    "<img src=\"./imgs/AirflowLogo.png\" width=200></td><td>\n",
    "<img src=\"./imgs/luigi.png\" width=150></td><td>\n",
    "<img src=\"./imgs/crontablogo.png\" width=250></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41177dba-96be-4589-8a61-1890b2a1ee6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Real-time pipelines\n",
    "\n",
    "Real-time data pipelines process new data as soon as it is available. The architecture for real-time data processing is very different from that of batched pipelines because data is treated as a **stream of events** instead of chunks of a record. \n",
    "\n",
    "Real-time pipelines are useful for applications that need to respond to new information close to instantly. \n",
    "\n",
    "<center><img src=\"./imgs/kafka.png\" width=200></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3fc63f-fa21-424a-8601-e0f03a8c6487",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Architecture / Orchestration\n",
    "\n",
    "All the previous layers are atomic. As such we can join them together in different ways for different purposes. This can massively increase performance if we're not processing the same raw data for each individual pipeline.\n",
    "\n",
    "<center><img src=\"./imgs/architecture.png\" width=300px height=300px style=\"margin: -20px\"><br><caption><em>A visual representation of the architecture layer</em></caption></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be54851-be5d-475b-adaf-f14001b5249f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### What technologies assist with orchestration\n",
    "\n",
    "Large scale orchestration is just pipelining pipelines, however the large and more complex the system the more important logging and error reporting become. That means simpler solutions such as `cron` will become more painful to maintain.\n",
    "\n",
    "<table style=\"text-align:center\">\n",
    "<tr><td>\n",
    "<img src=\"./imgs/AirflowLogo.png\" width=200></td><td>\n",
    "    <img src=\"./imgs/snowflake.png\" width=200></td><td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b60bf-9f0c-49d7-bbd7-b35cdbc39ee4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Versioning & CI/CD\n",
    "\n",
    "The most important thing to remember is that just like data science, for infrastructure to be effective it needs to constantly measured for performance, reviewed and iterated. \n",
    "\n",
    "<center><img src=\"./imgs/versioning.png\" width=400px height=400px style=\"margin: 0 0 -50px\"><br><caption><em>A visual representation of the architecture versioning</em></caption></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e6749-1238-411a-8519-c3fca6b9e0d7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### How to version control a pipeline \n",
    "\n",
    "Most of the tools we've discussed allow for versioning of a pipeline, the pipeline itself is just code and can versioned, tested and deployed just like any other project. <br><br>\n",
    "\n",
    "<center><img src=\"./imgs/gitlogo.png\" width=300></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d33ef1-7ec4-4cb8-a2ff-0f6554b5964c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### How to CI/CD a pipeline\n",
    "\n",
    "Continuous integration / Continuous development allows for changes to our code to be pushed to production incrementally. This can be made even safer with the use of a **development** environment that mirrors the setup of the production environment. \n",
    "\n",
    "As pipelines and orchestration are code it also possible to automate the testing of each deployment using unit and integration tests. \n",
    "\n",
    "**Unit tests** - Testing a small section of your code in isolation and,<br>\n",
    "**Integration tests** - Testing that the entire code works within the production environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f59af0-fe2a-428e-aa74-fd7b0872d6bc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Data Engineering key frameworks\n",
    "\n",
    "Every data engineering problem is different. If there is no need to process data in real-time then there is no need for a Kafka system. However below are some common tools and frameworks of which it wouldn't hurt to have a passing understanding.\n",
    "\n",
    "**Programming**: Python, SQL, Java/Scala<br>\n",
    "**Distributed Systems**: Hadoop<br>\n",
    "**Databases**: MySQL, MongoDB<br>\n",
    "**Data processing**: Spark<br>\n",
    "**Real-time data ecosystem**: Kafka<br>\n",
    "**Data orchestration**: Airflow<br>\n",
    "**Data science and ML**: pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b452f52-52f2-49d9-9507-cb26f01730c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Further reading \n",
    "\n",
    "Some resources for further reading are given below.\n",
    "<div style=\"float:left\"><a href=\"https://livebook.manning.com/book/effective-data-science-infrastructure/chapter-1/\"><img src=\"./imgs/manning_book.jpeg\" width=200px></a><br><center><em>Manning's Effective Data <br>Science Infrastructure.</em></center></div>\n",
    "<table style=\"padding-left:50px\">\n",
    "    <tr><th style=\"text-align:left\">Resources</th></tr>\n",
    "<td><a href=\"https://www.kdnuggets.com/2020/12/introduction-data-engineering.html\">An introduction to data engineering</a></td><tr>\n",
    "<td><a href=\"https://www.analyticsvidhya.com/blog/2018/11/data-engineer-comprehensive-list-resources-get-started/\">Data Engineer's comprehensive list of resources to get started.</a></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e12179e-3bdc-4c87-9320-8e4786717e00",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
