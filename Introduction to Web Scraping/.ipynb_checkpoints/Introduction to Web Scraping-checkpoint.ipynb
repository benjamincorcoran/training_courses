{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f434427-b833-4bcc-b4ea-d9f470d0df5f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Introduction to Web Scraping \n",
    "<br><br>\n",
    "**ONS / NISR**<br>\n",
    "2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed34f8c-f7d5-4cde-bb2c-db0e7f3cedf9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## What is web scraping \n",
    "\n",
    "Web scraping (Screen Scraping, Web Data Extraction, Web Harvesting etc.) is a technique used to automatically extract large amounts of data from websites and save it to a file or database. \n",
    "\n",
    "<center><img src=\"./imgs/web_scraping.png\"></center>\n",
    "\n",
    "The Internet is a data store of world's information - be it text, media or data in any other format. Every web page display data in one form or the other. Access to this data is crucial for the success of most businesses in the modern world. Unfortunately, most of this data is not open. Most websites do not provide the option to save the data which they display to your local storage, or to your own website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07c5bc4-7e8a-4271-bbf4-0ead1844fe69",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Why do web scraping \n",
    "\n",
    "Web Scraping is used for getting data. Data collection and analysis is important even for government, non-profit and educational institutions.\n",
    "\n",
    "The following are few of the many common applications of Web Scraping:\n",
    "\n",
    "1. In eCommerce, Web Scraping is used for competition price monitoring.\n",
    "\n",
    "2. In Marketing, Web Scraping is used for lead generation, to build phone and email lists for cold outreach.\n",
    "\n",
    "3. In Real Estate, Web Scraping is used to get property and agent/owner details.\n",
    "\n",
    "4. Web Scraping is used to collect training and testing data for Machine Learning projects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c208e68-e0b2-459f-9906-3f8dd7465ca7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Is Web Scraping Legal?\n",
    "\n",
    "One of the most frequent questions which comes to your mind once you have decided to scrape data is whether the process of web scraping is legal or not. Scraping data which is already available in public domain is **legal** as long as you use the data **ethically**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0523ba2f-1bdb-4d91-9a05-ee717ace5977",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Additional considerations \n",
    "\n",
    "Whilst the process of web scraping is legal, consideration should be given to the data that you're attempting to collect. Whilst it may be in the public domain, you may not have a legal standing to collect **personal** or **copyrighted** data. \n",
    "\n",
    "**Personal Data** - As a rule of thumb, it is recommended to have a lawful reason to obtain, store and use personal data without the user’s consent.\n",
    "\n",
    "**Copyrighted Data** - It is not illegal to scrape copyrighted data as long as you don’t plan to reuse or publish it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67547c5d-0e02-4bce-86e7-ec20e48e188d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## What are web pages?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0aab5-cda3-43b8-b213-e56e54e289e8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### HTML (Hypertext Markup Language)\n",
    "\n",
    "The backbone of any web page is HTML. This is a relatively simple markup language that uses `<tags>`, denoted by angle brackets, to markup different elements.\n",
    "\n",
    "Open https://www.statistics.gov.rw in any web browser and right click on the page and select `View Source`. \n",
    "\n",
    "<center><img src=\"./imgs/webscrape_view_source.png\" width=400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea88c2-d786-4963-b83f-080f5cb0c5d2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"./imgs/nisr_page_source.png\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b19e7c-b9d7-4d9c-9f65-52fc062d6c79",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Creating a Basic HTML page\n",
    "\n",
    "As `HTML` is just a series of `<tags>` written in plain text, we can create a web page that can be rendered in any browser just using a text editor. \n",
    "\n",
    "Create a new file called `my_webpage.html` and add the following text.\n",
    "```html\n",
    "<html> <!-- Open the HTML tag to declare that everything inside is HTML -->\n",
    "    <body> <!-- Open the body tag, this is where we can write visible elements -->\n",
    "        <h1>Page title</h1> <!-- h1 stands for Heading, see the use of </> to close the tag -->\n",
    "        <p>This is my webpage.</p> <!-- p stands for paragraph -->\n",
    "    </body> <!-- Close the body tag -->\n",
    "</html> <!-- Close the HTML tag-->\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ae2026-96f0-4920-a99e-75ff778e6a5e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"./imgs/my_webpage.png\" width=400 border=1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f46778-d40f-4758-bbfe-90a421fac381",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "There are plenty of other `<tags>` we can use in `HTML`, a full list can be found [here](https://www.tutorialrepublic.com/html-reference/html5-tags.php)\n",
    "\n",
    "Some common ones you'll see are listed below \n",
    "\n",
    "| Tag | Usage |\n",
    "| --- | --- | \n",
    "| `<div>` | Used to group elements together, or to provide structure to the web page |\n",
    "| `<span>` | Used to group elements and to provide structure behaves slightly differently to `<div>`| \n",
    "| `<img>` | Adds an image to the web page |\n",
    "| `<table>`, `<th>`, `<tr>`, `<td>` | Defines a table in HTML with the sub-elements defining the table header, table row and table cell respectively. |\n",
    "| `<a>` | Create a hyperlink around a specific element |\n",
    "| `<b>`, `<i>` | Create bold and italic elements respectively | \n",
    "| `<ol>`, `<ul>`, `<li>` | Create ordered and unordered lists where `<li>` tags list items. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890973c6-c647-4127-be80-4b8f283b6e68",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Lets create a second web page called `my_complex_webpage.html` that incorporates some of these other HTML elements. \n",
    "\n",
    "```html\n",
    "<html>\n",
    "    <body>\n",
    "        <h1>My Complex Webpage</h1>\n",
    "        <p>This is my more complex webpage with additional elements</p>\n",
    "        <a href=\"https://www.statistics.gov.rw\">This is a link to https://www.statistics.gov.rw</a>\n",
    "        <p>Below here is the NISR logo</p>\n",
    "        <img src=\"https://www.statistics.gov.rw/sites/default/files/images/logo.png\">\n",
    "        <h2>This is an unordered list of fruits</h2>\n",
    "        <ul>\n",
    "            <li>Apple</li>\n",
    "            <li>Banana</li>\n",
    "        </ul>\n",
    "        <h2>This is a HTML table</h2>\n",
    "        <table>\n",
    "            <tr><th>Column 1</th><th>Column2</th><th>Column3</th></tr>\n",
    "            <tr><td>1</td><td>2</td><td>3</td></tr>\n",
    "            <tr><td>4</td><td>5</td><td>6</td></tr>\n",
    "            <tr><td>7</td><td>8</td><td>9</td></tr>\n",
    "        </table>\n",
    "    </body>\n",
    "</html>\n",
    "```     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0fa4a0-6e2e-4af4-bf20-3bfead9eb031",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"./imgs/my_complex_webpage.png\" width=400 border=1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a4604-c4de-406e-a074-e17facb0b916",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Cascading Style Sheets (CSS)\n",
    "\n",
    "`<HTML>` is good for structure but it isn't very useful for styling elements on a web page. That's where Cascading Style Sheets (CSS) comes in. `CSS` is a separate language that allows us to apply \"styles\" to elements on our `HTML` web page. \n",
    "\n",
    "For example if we wanted to set the background of our web page to black and the font colour to white we could use the following CSS code. \n",
    "\n",
    "```css\n",
    "/* The body tells the browser to only apply the contained styles onto the <body> element */\n",
    "\n",
    "body {  \n",
    "    background: black; /* Set the page background to black */\n",
    "    color: white; /* Set the page font colour to white */\n",
    "}\n",
    "```\n",
    "\n",
    "Save the above code as `style.css`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742d27ca-f64c-4c0b-a983-236b2ad58df2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "There are two ways to add `CSS` to our web page. We can add it directly into the `HTML` document using the `<style>` tags. More commonly you'll see `CSS` stored in a separate `.css` file which is linked in the `.html` file using the `<head>` and `<link>` tags. \n",
    "\n",
    "The `<head>` tag is like the body tag, but used for store additional meta information that isn't directly displayed on the page. \n",
    "\n",
    "```html\n",
    "<html>\n",
    "    <head>\n",
    "        <link rel='stylesheet' href='style.css'>\n",
    "    </head>\n",
    "    <body>\n",
    "        ...\n",
    "    </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "Create a copy of `my_complex_webpage.html` and add the `<head>` and `<link>` tags as described above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ff396a-330c-4a5a-837b-d4d6b3fd7d11",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"./imgs/css.png\" width=400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f90bc8-c942-4132-ac6f-7ffe88a35ca3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "`CSS` is able to define styles not just for **types** of elements (i.e. `<body>`, `<li>`, `<p>`) but it can also define **classes** we can be applied to numerous elements. \n",
    "\n",
    "```css \n",
    "/* The \".\" at the start of the definition tells HTML to apply this style to any elements */\n",
    "/* that have the specified class name. */\n",
    "\n",
    ".red_text {\n",
    "    color: red;\n",
    "}\n",
    "```\n",
    "\n",
    "Add this style to your `style.css` file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad60778f-c7bd-41c2-bdfe-0de10b59223a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We can now use the the `class` attribute on any HTML element to assign this specific style to specific elements. \n",
    "\n",
    "```html\n",
    "<html>\n",
    "    <head>\n",
    "        <link rel='stylesheet' href='style.css'>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>My Complex Webpage</h1>\n",
    "        <p class=\"red_text\">This is my more complex webpage with additional elements</p>\n",
    "        ...\n",
    "        <h2 class=\"red_text\">This is an unordered list of fruits</h2>\n",
    "        <ul>\n",
    "            <li class=\"red_text\">Apple</li>\n",
    "            <li>Banana</li>\n",
    "        </ul>\n",
    "        ...\n",
    "    <head>\n",
    "<html>\n",
    "```\n",
    "\n",
    "Edit your copy of `my_complex_webpage.html` to include the `class` attribute on some tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330c7516-8eed-4283-9e7c-93f6ccd2dad2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"./imgs/css_classes.png\" width=400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d7e045-0e88-48f5-94c0-c9ef0f4c18dc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Congrats, you're officially a web designer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16bed48-d05d-46ef-a480-562ba8a9cd6c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Scraping web pages with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc126ed-be02-41ae-838c-c32e33fa15b3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Pandas has a built in function called `read_html` that allows us to read HTML tables directly from a web page. We can try this with the web page we just finished creating by using the following code. \n",
    "\n",
    "```python \n",
    "import pandas as pd \n",
    "df = pd.read_html('./my_complex_webpage.html')\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d6c4f9-d1e0-446f-ac70-6e60b41a9dfc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Column 1  Column2  Column3\n",
      "0         1        2        3\n",
      "1         4        5        6\n",
      "2         7        8        9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_html('./assets/my_complex_webpage.html')\n",
    "\n",
    "print(df[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae1e4f0-547e-4be8-a7a2-4da14cf7e538",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Pandas correctly found our table parsing out all our other `HTML`, but by default `read_html` will return a `list` of all tables that pandas can find on the web page, even if its only one. \n",
    "\n",
    "Pandas is also able to filter out any of the CSS that's been applied to our tables as well, returning on the data. \n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Select the first / only dataframe in the list\n",
    "df_no_css = pd.read_html('./my_complex_webpage.html')[0]\n",
    "df_css = pd.read_html('./my_complex_webpage_with_css.html')[0]\n",
    "\n",
    "# This will error if the dataframes aren't identical.\n",
    "pd.testing.assert_frame_equal(df_no_css, df_css)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66cb29ee-4336-4980-af73-52f452aa5e41",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Select the first / only dataframe in the list\n",
    "df_no_css = pd.read_html('./assets/my_complex_webpage.html')[0]\n",
    "df_css = pd.read_html('./assets/my_complex_webpage_with_css.html')[0]\n",
    "\n",
    "# This will error if the dataframes aren't identical.\n",
    "pd.testing.assert_frame_equal(df_no_css, df_css)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a6dc3f-0c3a-4a03-b815-c9ff886f3b7a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Real world application \n",
    "\n",
    "Obviously real world websites are much messier than our example page, so we will also need to employ some basic data cleaning techniques to deal with these real world examples. \n",
    "\n",
    "Lets look at the wikipedia page for the [Rwandan Men's National Basketball Team](https://en.wikipedia.org/wiki/Rwanda_men%27s_national_basketball_team). There are lots of different tables, in different styles, some with images, some with complex headers. We can throw the URL directly into to `read_html` and see what comes out.  \n",
    "\n",
    "```python \n",
    "import pandas as pd \n",
    "\n",
    "basketball_tables = pd.read_html('https://en.wikipedia.org/wiki/Rwanda_men%27s_national_basketball_team')\n",
    "\n",
    "print(f'Tables found: {len(basketball_tables)}')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffdae1f9-ecf6-4757-987a-66860ef68d4c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables found: 13\n"
     ]
    }
   ],
   "source": [
    "basketball_tables = pd.read_html('https://en.wikipedia.org/wiki/Rwanda_men%27s_national_basketball_team')\n",
    "print(f'Tables found: {len(basketball_tables)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5192ee3-cd23-4f02-a9ae-ffb7da1c94fe",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Often web developers will use `<table>` tags as a structural element, rather than to explicitly display some data. Note that the `0th` index in `basketball_tables` doesn't refer to the first visible table, but instead the information card in the top left corner of the page. \n",
    "\n",
    "<center><img src=\"./imgs/wiki_info_card.png\" width=200></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d85f8fb-7bc3-48ed-a7e1-e2728d692678",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Looking through the 13 parsed tables, we can find the current roster table at position `4`, but as Wikipedia can change we want to be able to write some code that **always** selects the roster table. We can do that using the keyword `match`. The `match` keyword will return any table containing the string passed. \n",
    "\n",
    "Once we've done that we can add our usual `skiprows` and `header` arguments to make sure the correct row is being used as the header of the table. \n",
    "\n",
    "```python \n",
    "url = 'https://en.wikipedia.org/wiki/Rwanda_men%27s_national_basketball_team'\n",
    "\n",
    "roster = pd.read_html(url, \n",
    "                      match=\"Rwanda men's national basketball team roster\", \n",
    "                      skiprows=1, \n",
    "                      header=2)[0]\n",
    "roster.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15866970-6344-427e-a754-155abdaae2b3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos.</th>\n",
       "      <th>No.</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age – Date of birth</th>\n",
       "      <th>Height</th>\n",
       "      <th>Club</th>\n",
       "      <th>Ctr.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PG</td>\n",
       "      <td>4</td>\n",
       "      <td>Jean Nshobozwabyose</td>\n",
       "      <td>23 –</td>\n",
       "      <td>1.83 m (6 ft 0 in)</td>\n",
       "      <td>Patriots</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>5</td>\n",
       "      <td>Ntore Habimana</td>\n",
       "      <td>24 –</td>\n",
       "      <td>1.96 m (6 ft 5 in)</td>\n",
       "      <td>Wilfrid Laurier Golden Hawks</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SG</td>\n",
       "      <td>6</td>\n",
       "      <td>Steven Hagumintwari</td>\n",
       "      <td>27 –</td>\n",
       "      <td>1.93 m (6 ft 4 in)</td>\n",
       "      <td>Patriots</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SG</td>\n",
       "      <td>7</td>\n",
       "      <td>Armel Sangwe</td>\n",
       "      <td>24 –</td>\n",
       "      <td>1.90 m (6 ft 3 in)</td>\n",
       "      <td>Espoir</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SG</td>\n",
       "      <td>8</td>\n",
       "      <td>Emile Kazeneza</td>\n",
       "      <td>20 –</td>\n",
       "      <td>2.01 m (6 ft 7 in)</td>\n",
       "      <td>William Carey University</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pos.  No.                 Name Age – Date of birth              Height  \\\n",
       "0   PG    4  Jean Nshobozwabyose                23 –  1.83 m (6 ft 0 in)   \n",
       "1    G    5       Ntore Habimana                24 –  1.96 m (6 ft 5 in)   \n",
       "2   SG    6  Steven Hagumintwari                27 –  1.93 m (6 ft 4 in)   \n",
       "3   SG    7         Armel Sangwe                24 –  1.90 m (6 ft 3 in)   \n",
       "4   SG    8       Emile Kazeneza                20 –  2.01 m (6 ft 7 in)   \n",
       "\n",
       "                           Club  Ctr.  \n",
       "0                      Patriots   NaN  \n",
       "1  Wilfrid Laurier Golden Hawks   NaN  \n",
       "2                      Patriots   NaN  \n",
       "3                        Espoir   NaN  \n",
       "4      William Carey University   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Rwanda_men%27s_national_basketball_team'\n",
    "\n",
    "roster = pd.read_html(url, \n",
    "                      match=\"Rwanda men's national basketball team roster\", \n",
    "                      skiprows=1, \n",
    "                      header=2)[0]\n",
    "roster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31309aea-4282-4e31-9cea-28b0f4f44250",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We've now code that can scrape that table whenever we want. However, something looks a little wrong with the `Age - Date of Birth` column. Not all the data has been scraped, notably the actual dates of birth. \n",
    "\n",
    "<center><img src=\"./imgs/display_none.png\" width=300></center>\n",
    "\n",
    "This is because there is **hidden** data within these cells. Pandas will stop scraping a cell if it hits hidden data unless we explicitly tell it not to using `displayed_only=False`. \n",
    "\n",
    "```python\n",
    "url = 'https://en.wikipedia.org/wiki/Rwanda_men%27s_national_basketball_team'\n",
    "\n",
    "roster = pd.read_html(url, \n",
    "                      match=\"Rwanda men's national basketball team roster\", \n",
    "                      skiprows=1, \n",
    "                      header=2,\n",
    "                      displayed_only=False)[0]\n",
    "roster.head()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7192eda0-39da-4c9a-b313-23e0f1c3dc51",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos.</th>\n",
       "      <th>No.</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age – Date of birth</th>\n",
       "      <th>Height</th>\n",
       "      <th>Club</th>\n",
       "      <th>Ctr.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PG</td>\n",
       "      <td>4</td>\n",
       "      <td>Jean Nshobozwabyose</td>\n",
       "      <td>23 – (1998-06-26)26 June 1998</td>\n",
       "      <td>1.83 m (6 ft 0 in)</td>\n",
       "      <td>Patriots</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>5</td>\n",
       "      <td>Ntore Habimana</td>\n",
       "      <td>24 – (1997-08-15)15 August 1997</td>\n",
       "      <td>1.96 m (6 ft 5 in)</td>\n",
       "      <td>Wilfrid Laurier Golden Hawks</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SG</td>\n",
       "      <td>6</td>\n",
       "      <td>Steven Hagumintwari</td>\n",
       "      <td>27 – (1993-10-01)1 October 1993</td>\n",
       "      <td>1.93 m (6 ft 4 in)</td>\n",
       "      <td>Patriots</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SG</td>\n",
       "      <td>7</td>\n",
       "      <td>Armel Sangwe</td>\n",
       "      <td>24 – (1997-04-15)15 April 1997</td>\n",
       "      <td>1.90 m (6 ft 3 in)</td>\n",
       "      <td>Espoir</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SG</td>\n",
       "      <td>8</td>\n",
       "      <td>Emile Kazeneza</td>\n",
       "      <td>20 – (2000-08-30)30 August 2000</td>\n",
       "      <td>2.01 m (6 ft 7 in)</td>\n",
       "      <td>William Carey University</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pos.  No.                 Name              Age – Date of birth  \\\n",
       "0   PG    4  Jean Nshobozwabyose    23 – (1998-06-26)26 June 1998   \n",
       "1    G    5       Ntore Habimana  24 – (1997-08-15)15 August 1997   \n",
       "2   SG    6  Steven Hagumintwari  27 – (1993-10-01)1 October 1993   \n",
       "3   SG    7         Armel Sangwe   24 – (1997-04-15)15 April 1997   \n",
       "4   SG    8       Emile Kazeneza  20 – (2000-08-30)30 August 2000   \n",
       "\n",
       "               Height                          Club  Ctr.  \n",
       "0  1.83 m (6 ft 0 in)                      Patriots   NaN  \n",
       "1  1.96 m (6 ft 5 in)  Wilfrid Laurier Golden Hawks   NaN  \n",
       "2  1.93 m (6 ft 4 in)                      Patriots   NaN  \n",
       "3  1.90 m (6 ft 3 in)                        Espoir   NaN  \n",
       "4  2.01 m (6 ft 7 in)      William Carey University   NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Rwanda_men%27s_national_basketball_team'\n",
    "\n",
    "roster = pd.read_html(url, \n",
    "                      match=\"Rwanda men's national basketball team roster\", \n",
    "                      skiprows=1, \n",
    "                      header=2,\n",
    "                      displayed_only=False)[0]\n",
    "roster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1047fc1e-e8df-4854-be50-feb6c06afe25",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "There we go, now we've got all the data we want from the table. Unfortunately, as Wikipedia has used images rather than text to represent the countries of the players, we're unable to scrape them using pandas. \n",
    "\n",
    "We'll look at other methods to get this data later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d514b1c9-6851-4585-a5e8-68be6c6fb2b5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Limitations of Pandas for web scraping\n",
    "\n",
    "Obviously we've seem some of the limitations already, notably pandas not being to parse images and it collecting tables that aren't relevant to our intended goal. However in most web pages, the data we want to scrape wont be formatted into a nice table for us. If it isn't in `<table>` tags then we wont be able to scrape it using pandas. \n",
    "\n",
    "- Good for websites with predefined tables \n",
    "- Wont collection information that isn't text\n",
    "\n",
    "However there are lots of other methods for accessing that data, but first we need to understand a little of how websites function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb10fe7c-aec6-4c00-b2f1-14c475271f66",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## How do web sites work?\n",
    "\n",
    "Now that we understand the structure of a web page, we can see how it might be extremely tedious to create every individual web page, especially if we want to include regularly changing data. \n",
    "\n",
    "That's why most web pages are created **dynamically**. This means that the web page is put together **on-the-fly** whenever someone requests to see it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2caf46-b467-4c3f-b3e2-a245f8791314",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Client-side versus Server-side scripting\n",
    "\n",
    "Web pages are usually generated in one of two ways, via **client-side** scripting or via **server-side** script. This defines where the data gets turned into HTML elements. If it is on the **client-side**, then the raw data is sent directly to our browser and our computer creates the web page, if it is **server-side** then we don't ever see the raw data, only the computed HTML elements.\n",
    "\n",
    "<table>\n",
    "    <tr><th>Client-side Scripting</th><th>Server-side scripting</th>\n",
    "    <tr><td><img src=\"./imgs/client_side.png\" width=400></td><td><img src=\"./imgs/server_side.png\" width=400></td></tr>\n",
    "    <tr><td>Data usually processed with Javascript</td><td>Data can be processed with php, Javascript, python etc.</td></tr>\n",
    "    <tr><td>Is possible to see the underlying data</td><td>Is not possible to see the underlying data</td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0819b02-228c-4912-a3dd-5b6bf6377be2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Inspecting a web page's creation\n",
    "\n",
    "We've already looked at a web page's source by using `View page source`. There is a more advanced tool for working with web pages built into most browsers, usually called `Inspect`. `Right-Click > Inspect`. Lets inspect the wikipedia page for the [Rwandan Men's National Basketball Team](https://en.wikipedia.org/wiki/Rwanda_men%27s_national_basketball_team).\n",
    "\n",
    "We'll come back to the `Elements` page later, for now we want to look at the `Network Tab` on the toolbar.\n",
    "<center><img src=\"./imgs/inspect.png\" width=400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89130abc-923a-4acf-acda-1a6489d8c4c1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "The network tab records all the requests that go between our browser and the server (as well as other servers) in the production of the web page. When you first open the page it will be blank. Refreshing the browser page will cause the network tab to record all the different requests that occur. \n",
    "\n",
    "<table>\n",
    "    <tr><td><img src=\"./imgs/network.png\" width=400></td><td><img src=\"./imgs/network_recorded.png\" width=400></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd82f3a8-b054-469c-a9ef-0e72603b0926",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Clicking on any one of the files that has been requested, you can see the full HTTP request (more on this later) as well as a preview and actual full response from the server for that request. Looking at the response for the first request (the page) we can see that the data was included directly in the page as HTML. This implies that this particular page was processed **server-side**. Another clue was the reference to `php` which is an exclusively server-side language. \n",
    "\n",
    "<table><tr>\n",
    "    <td><img src=\"./imgs/network_preview.png\" width=400></td>\n",
    "    <td><img src=\"./imgs/serverside_table.png\" width=500></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf9740b-1a3e-4d8a-a271-9bb6a5f1173e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Client Side Example\n",
    "\n",
    "Lets look at the [NBA website](https://www.nba.com/stats/leaders/?SeasonType=Regular%20Season) instead. This page shows us statistics for the regular season for players in the NBA ordered by the number of points.\n",
    "\n",
    "<center><img src=\"./imgs/nba_scoreboard.png\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0a8ad1-bff0-4e44-95ab-3f14e33d8ff2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We could try and scrape this data using `pandas` but lets see if we can find the source of this data first. Opening up the `Inspect` tool we can look at the `Network` tab to try and find where this data is loaded from. \n",
    "\n",
    "<center><img src=\"./imgs/inspect_fetch.png\" width=500></center>\n",
    "\n",
    "There are **a lot** of files that are loaded as part of this web page. We can reduce the number we need to search through by using the built in filters on the `Network` tab. Lets look at `Fetch/XHR` which filters the list to requests usually associated with data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c5e726-0efa-41dc-96a4-e2d95baca9da",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Looking through this shorter list of files, one stands out as potentially containing the data that we want to extract from the web page. \n",
    "\n",
    "We can click on the file and the the `Response` tab to see what information is sent to our browser from this file. Looking at the response we can see that the data that goes into our table is not encoded into `HTML` so we can be relatively sure that web page is generated at least partly on the client side.  \n",
    "\n",
    "<table>\n",
    "    <tr><td><img src=\"./imgs/inspect_datarequest.png\" width=400></td>\n",
    "        <td><img src=\"./imgs/inspect_data.png\" width=600></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30823a4-01ac-4d12-8b2d-768d0c24d853",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Key takeways \n",
    "\n",
    "* If a website is processed **client** side then it may be possible to get at the data that creates the web page **without** having to parse `HTML`\n",
    "* However some web scraping programs wont be able to execute the client side code, meaning we have to use a web browser. \n",
    "* If a website is processed **server** side then it **is not** possible to get the data without having to parse the `HTML` served. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb40b8ea-03c6-4f82-9d7b-2408252fc586",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Requests Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529aee1e-4987-4bf5-b88c-005befe4a59c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "The `requests` library is the de-facto standard for making `HTTP requests`, it abstracts away all of the complexity we just saw using the `Inspect` tool. `requests` is a built in library so there is no need to install. \n",
    "\n",
    "The `requests` library is very powerful, but importantly we can use it to do in python what our web browser was doing when it loaded in our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d152497f-a8f0-4eb7-a7a2-5463c37fef21",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Returning to our [NBA example](https://www.nba.com/stats/leaders/?SeasonType=Regular%20Season). Looking at the `Network` tab shows us all the of the `HTTP` requests that have been made in the process of creating the web page that we see.\n",
    "\n",
    "If we look in the `Headers` tab, we can see the form that this HTTP request took.\n",
    "\n",
    "The `URL` had the request information encoded into it, we can also see that the request type is `GET`. \n",
    "\n",
    "<center><img src=\"./imgs/inspect_header.png\" width=400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaf8697-d1c6-474a-9886-b2a5f6dd04f7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Lets see what happens if we recreate that request in Python using the `requests` library. First we need to get the request URL from the header tab. We also need to note that the method is `GET`. \n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "url = 'https://stats.nba.com/stats/leagueLeaders?LeagueID=00&PerMode=PerGame&Scope=S&Season=2021-22&SeasonType=Regular+Season&StatCategory=PTS'\n",
    "\n",
    "# We are using the .get method to match the GET HTTP request \n",
    "# we also include the .json() method to return to us the response \n",
    "# from the request as a python dictionary.\n",
    "response = requests.get(url).json()\n",
    "\n",
    "print(response)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6291d28e-5962-405a-9c8b-88ed44e6d31c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://stats.nba.com/stats/leagueLeaders?LeagueID=00&PerMode=PerGame&Scope=S&Season=2021-22&SeasonType=Regular+Season&StatCategory=PTS'\n",
    "\n",
    "# We are using the .get method to match the GET HTTP request \n",
    "# we also include the .json() method to return to us the response \n",
    "# from the request as a python dictionary.\n",
    "response = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d82e8a-4004-4b75-a1e9-85ab4715a5c9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We can see that the result of that command is the same as the data we saw using the `Inspect` tool. We can look through this nested dictionary object to try and understand the structure of the response. **It is important to note that not every response will look the same**. You'll need to dig into each response to extract the data as and when.  \n",
    "\n",
    "We can look through the object and see if there is a way to convert information into a table that we can use. \n",
    "\n",
    "```python \n",
    "print(response.keys())\n",
    "print(response['resultSet'].keys())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25ae08a8-f756-4d99-9573-82a5e1c2f0c4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['resource', 'parameters', 'resultSet'])\n",
      "dict_keys(['name', 'headers', 'rowSet'])\n"
     ]
    }
   ],
   "source": [
    "print(response.keys())\n",
    "print(response['resultSet'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea02b9d-d565-4802-869b-969d2fbedfb7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Looking at the keys in the data, we can see that the response contains three objects called `resource`, `parameters` and `resultSet`. `resource` and `parameters` are metadata about the table that we've just requested. `resultSet` contains another dictionary with the keys `name`, `headers` and `rowSet`. `rowSet` is a list of list, each representing a row of data and the `headers` contains a list of column headers. \n",
    "\n",
    "We can put these together using `pandas` into a dataframe very easily. \n",
    "\n",
    "```python \n",
    "import requests\n",
    "import pandas as pd \n",
    "\n",
    "url = 'https://stats.nba.com/stats/leagueLeaders?LeagueID=00&PerMode=PerGame&Scope=S&Season=2021-22&SeasonType=Regular+Season&StatCategory=PTS'\n",
    "\n",
    "response = requests.get(url).json()\n",
    "table_headers = response['resultSet']['headers']\n",
    "table_data = response['resultSet']['rowSet']\n",
    "\n",
    "df = pd.DataFrame(table_data, columns=table_headers)\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1380088f-152e-49bc-8468-0d31e2486bbd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER_ID</th>\n",
       "      <th>RANK</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG_PCT</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>...</th>\n",
       "      <th>FT_PCT</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PTS</th>\n",
       "      <th>EFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201142</td>\n",
       "      <td>1</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>BKN</td>\n",
       "      <td>12</td>\n",
       "      <td>34.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0.585</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>29.5</td>\n",
       "      <td>31.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201939</td>\n",
       "      <td>2</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>GSW</td>\n",
       "      <td>11</td>\n",
       "      <td>33.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.434</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>27.4</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202331</td>\n",
       "      <td>3</td>\n",
       "      <td>Paul George</td>\n",
       "      <td>LAC</td>\n",
       "      <td>11</td>\n",
       "      <td>35.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.456</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>26.7</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203507</td>\n",
       "      <td>4</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>MIL</td>\n",
       "      <td>12</td>\n",
       "      <td>32.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.496</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688</td>\n",
       "      <td>1.9</td>\n",
       "      <td>9.9</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>31.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1629630</td>\n",
       "      <td>5</td>\n",
       "      <td>Ja Morant</td>\n",
       "      <td>MEM</td>\n",
       "      <td>11</td>\n",
       "      <td>35.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.485</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>1629216</td>\n",
       "      <td>275</td>\n",
       "      <td>Gabe Vincent</td>\n",
       "      <td>MIA</td>\n",
       "      <td>10</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>203085</td>\n",
       "      <td>276</td>\n",
       "      <td>Austin Rivers</td>\n",
       "      <td>DEN</td>\n",
       "      <td>9</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1630541</td>\n",
       "      <td>276</td>\n",
       "      <td>Moses Moody</td>\n",
       "      <td>GSW</td>\n",
       "      <td>9</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>1626161</td>\n",
       "      <td>278</td>\n",
       "      <td>Willie Cauley-Stein</td>\n",
       "      <td>DAL</td>\n",
       "      <td>11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>1630215</td>\n",
       "      <td>279</td>\n",
       "      <td>Jared Butler</td>\n",
       "      <td>UTA</td>\n",
       "      <td>10</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PLAYER_ID  RANK                 PLAYER TEAM  GP   MIN   FGM   FGA  \\\n",
       "0       201142     1           Kevin Durant  BKN  12  34.4  11.2  19.1   \n",
       "1       201939     2          Stephen Curry  GSW  11  33.6   8.6  19.9   \n",
       "2       202331     3            Paul George  LAC  11  35.3  10.0  21.9   \n",
       "3       203507     4  Giannis Antetokounmpo  MIL  12  32.9   9.5  19.2   \n",
       "4      1629630     5              Ja Morant  MEM  11  35.3  10.0  20.6   \n",
       "..         ...   ...                    ...  ...  ..   ...   ...   ...   \n",
       "274    1629216   275           Gabe Vincent  MIA  10   8.9   0.8   2.0   \n",
       "275     203085   276          Austin Rivers  DEN   9  12.4   0.8   3.0   \n",
       "276    1630541   276            Moses Moody  GSW   9   6.8   0.8   2.0   \n",
       "277    1626161   278    Willie Cauley-Stein  DAL  11  10.0   0.7   1.7   \n",
       "278    1630215   279           Jared Butler  UTA  10   4.6   0.5   1.9   \n",
       "\n",
       "     FG_PCT  FG3M  ...  FT_PCT  OREB  DREB   REB  AST  STL  BLK  TOV   PTS  \\\n",
       "0     0.585   1.9  ...   0.829   0.5   8.0   8.5  5.0  0.6  0.7  3.5  29.5   \n",
       "1     0.434   5.0  ...   0.949   0.8   5.6   6.5  6.5  1.6  0.6  3.1  27.4   \n",
       "2     0.456   3.2  ...   0.867   0.5   7.3   7.8  5.4  2.5  0.5  4.5  26.7   \n",
       "3     0.496   1.3  ...   0.688   1.9   9.9  11.8  6.0  1.1  1.8  3.0  26.6   \n",
       "4     0.485   1.7  ...   0.779   1.3   4.5   5.7  7.3  1.7  0.3  4.0  26.5   \n",
       "..      ...   ...  ...     ...   ...   ...   ...  ...  ...  ...  ...   ...   \n",
       "274   0.400   0.1  ...   1.000   0.3   0.5   0.8  1.7  0.2  0.0  0.6   1.9   \n",
       "275   0.259   0.2  ...   0.500   0.4   0.7   1.1  0.8  0.3  0.1  0.7   1.9   \n",
       "276   0.389   0.2  ...   0.500   0.0   0.9   0.9  0.3  0.0  0.1  0.1   1.9   \n",
       "277   0.421   0.0  ...   0.000   0.7   1.6   2.4  0.5  0.3  0.0  0.2   1.5   \n",
       "278   0.263   0.2  ...   0.500   0.0   0.6   0.6  0.6  0.0  0.5  0.6   1.4   \n",
       "\n",
       "      EFF  \n",
       "0    31.8  \n",
       "1    28.0  \n",
       "2    26.0  \n",
       "3    31.8  \n",
       "4    25.5  \n",
       "..    ...  \n",
       "274   2.8  \n",
       "275   1.2  \n",
       "276   1.8  \n",
       "277   3.4  \n",
       "278   0.9  \n",
       "\n",
       "[279 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "\n",
    "url = 'https://stats.nba.com/stats/leagueLeaders?LeagueID=00&PerMode=PerGame&Scope=S&Season=2021-22&SeasonType=Regular+Season&StatCategory=PTS'\n",
    "\n",
    "response = requests.get(url).json()\n",
    "table_headers = response['resultSet']['headers']\n",
    "table_data = response['resultSet']['rowSet']\n",
    "\n",
    "df = pd.DataFrame(table_data, columns=table_headers)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff610b-7122-4c6d-8c02-aa0091f86814",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "If we look closer at the URL, we can see it encodes a lot of arguments, these arguments look very similar to the filters that are available on the web page. \n",
    "\n",
    "```\n",
    "https://stats.nba.com/stats/leagueLeaders?\n",
    "    LeagueID=00&\n",
    "    PerMode=PerGame&\n",
    "    Scope=S&\n",
    "    Season=2021-22&\n",
    "    SeasonType=Regular+Season&\n",
    "    StatCategory=PTS\n",
    "```\n",
    "\n",
    "<img src='./imgs/nba_filters.png'>\n",
    "\n",
    "If we change \"PerGame\" to \"Totals\" and re-run our code then we should get data that would inform website table had we selected that option. What we've done here is discover the `API` that sits behind the NBA website and we can exploit this to extract data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce27983-04a7-42cc-bb83-0efd6f9c707f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER_ID</th>\n",
       "      <th>RANK</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG_PCT</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>...</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>EFF</th>\n",
       "      <th>AST_TOV</th>\n",
       "      <th>STL_TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201142</td>\n",
       "      <td>1</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>BKN</td>\n",
       "      <td>12</td>\n",
       "      <td>413</td>\n",
       "      <td>134</td>\n",
       "      <td>229</td>\n",
       "      <td>0.585</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>354</td>\n",
       "      <td>381</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203507</td>\n",
       "      <td>2</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>MIL</td>\n",
       "      <td>12</td>\n",
       "      <td>395</td>\n",
       "      <td>114</td>\n",
       "      <td>230</td>\n",
       "      <td>0.496</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>142</td>\n",
       "      <td>72</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>319</td>\n",
       "      <td>381</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201939</td>\n",
       "      <td>3</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>GSW</td>\n",
       "      <td>11</td>\n",
       "      <td>370</td>\n",
       "      <td>95</td>\n",
       "      <td>219</td>\n",
       "      <td>0.434</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>17</td>\n",
       "      <td>301</td>\n",
       "      <td>308</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202331</td>\n",
       "      <td>4</td>\n",
       "      <td>Paul George</td>\n",
       "      <td>LAC</td>\n",
       "      <td>11</td>\n",
       "      <td>388</td>\n",
       "      <td>110</td>\n",
       "      <td>241</td>\n",
       "      <td>0.456</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>59</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>31</td>\n",
       "      <td>294</td>\n",
       "      <td>286</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1629630</td>\n",
       "      <td>5</td>\n",
       "      <td>Ja Morant</td>\n",
       "      <td>MEM</td>\n",
       "      <td>11</td>\n",
       "      <td>388</td>\n",
       "      <td>110</td>\n",
       "      <td>227</td>\n",
       "      <td>0.485</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>292</td>\n",
       "      <td>281</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>1630536</td>\n",
       "      <td>418</td>\n",
       "      <td>Sharife Cooper</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>1629605</td>\n",
       "      <td>418</td>\n",
       "      <td>Tacko Fall</td>\n",
       "      <td>CLE</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>1628962</td>\n",
       "      <td>418</td>\n",
       "      <td>Udoka Azubuike</td>\n",
       "      <td>UTA</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>1630176</td>\n",
       "      <td>418</td>\n",
       "      <td>Vernon Carey Jr.</td>\n",
       "      <td>CHA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>1627782</td>\n",
       "      <td>418</td>\n",
       "      <td>Wayne Selden</td>\n",
       "      <td>NYK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PLAYER_ID  RANK                 PLAYER TEAM  GP  MIN  FGM  FGA  FG_PCT  \\\n",
       "0       201142     1           Kevin Durant  BKN  12  413  134  229   0.585   \n",
       "1       203507     2  Giannis Antetokounmpo  MIL  12  395  114  230   0.496   \n",
       "2       201939     3          Stephen Curry  GSW  11  370   95  219   0.434   \n",
       "3       202331     4            Paul George  LAC  11  388  110  241   0.456   \n",
       "4      1629630     5              Ja Morant  MEM  11  388  110  227   0.485   \n",
       "..         ...   ...                    ...  ...  ..  ...  ...  ...     ...   \n",
       "443    1630536   418         Sharife Cooper  ATL   2    7    0    3   0.000   \n",
       "444    1629605   418             Tacko Fall  CLE   3    3    0    1   0.000   \n",
       "445    1628962   418         Udoka Azubuike  UTA   2    2    0    0   0.000   \n",
       "446    1630176   418       Vernon Carey Jr.  CHA   1    1    0    1   0.000   \n",
       "447    1627782   418           Wayne Selden  NYK   1    1    0    0   0.000   \n",
       "\n",
       "     FG3M  ...  REB  AST  STL  BLK  TOV  PF  PTS  EFF  AST_TOV  STL_TOV  \n",
       "0      23  ...  102   60    7    8   42  16  354  381     1.43     0.17  \n",
       "1      16  ...  142   72   13   21   36  36  319  381     2.00     0.36  \n",
       "2      55  ...   71   72   18    7   34  17  301  308     2.12     0.53  \n",
       "3      35  ...   86   59   28    5   49  31  294  286     1.20     0.57  \n",
       "4      19  ...   63   80   19    3   44  16  292  281     1.82     0.43  \n",
       "..    ...  ...  ...  ...  ...  ...  ...  ..  ...  ...      ...      ...  \n",
       "443     0  ...    0    2    0    0    1   0    0   -2     2.00     0.00  \n",
       "444     0  ...    2    0    0    0    1   0    0    0     0.00     0.00  \n",
       "445     0  ...    0    0    0    0    0   0    0    0     0.00     0.00  \n",
       "446     0  ...    1    0    0    0    0   0    0    0     0.00     0.00  \n",
       "447     0  ...    0    0    0    0    0   0    0    0     0.00     0.00  \n",
       "\n",
       "[448 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "\n",
    "per_mode = 'Totals'\n",
    "\n",
    "url = f'https://stats.nba.com/stats/leagueLeaders?LeagueID=00&PerMode={per_mode}&Scope=S&Season=2021-22&SeasonType=Regular+Season&StatCategory=PTS'\n",
    "\n",
    "response = requests.get(url).json()\n",
    "table_headers = response['resultSet']['headers']\n",
    "table_data = response['resultSet']['rowSet']\n",
    "\n",
    "df = pd.DataFrame(table_data, columns=table_headers)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a599ce-8f28-4771-a6b4-97905dfa8172",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Beautiful Soup Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c426d951-1df9-47c7-985a-0090e1ed0b61",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Sometimes, in-fact most of the time, the information that we want to scrape wont be found neatly formatted into a table. What we need to be able to do is extract the relevant information programatically from non-table objects. Enter `beautifulsoup`. `beautifulsoup` is a `HTML` parsing library for python, it allows us to pull out all the relevant information from a web page using a nice and easy to use syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37285775-2d71-4f8d-8a38-6c2830213921",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "`beautifulsoup` does not come as part of the standard python installation so we need to `pip` install it. We can do this inside our jupyternotebook using \n",
    "\n",
    "```\n",
    "!pip install beautifulsoup4\n",
    "```\n",
    "\n",
    "Or just on the command line by running the same command, without the `!` at the begining of the line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46e01d8c-4ddd-4371-927d-095abe60da67",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/miniconda3/lib/python3.9/site-packages (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/miniconda3/lib/python3.9/site-packages (from beautifulsoup4) (2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f8dfa8-0494-485b-8563-cb27a4e3bf27",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Once we've installed beautiful soup we can start to use it to parse our HTML data. Lets start again by parsing the web page that we made earlier. \n",
    "\n",
    "```python\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "with open('./my_complex_webpage.html', 'r') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "\n",
    "print(soup)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82f6fd19-14c7-4722-b1ff-5572c406fa9f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<link href=\"style.css\" rel=\"stylesheet\"/>\n",
      "</head>\n",
      "<body>\n",
      "<h1>My Complex Webpage</h1>\n",
      "<p class=\"red_text\">This is my more complex webpage with additional elements</p>\n",
      "<a href=\"https://www.statistics.gov.rw\">This is a link to https://www.statistics.gov.rw</a>\n",
      "<p>Below here is the NISR lo\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "with open('./assets/my_complex_webpage_with_css_classes.html', 'r') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "\n",
    "print(str(soup)[:300] + '\\n...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeadc968-3d75-4afe-9801-33e39f85be2a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "`beautifulsoup` has lots of functions that make it very easy to extract information from a HTML page. The most useful of which is the `find_all()` method. Full documentation for the `find_all` method can be found [here](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all).\n",
    "\n",
    "Before we were able to use pandas to extract the HTML table very easily, but what if we were more interested in the \"Unordered list of fruits\". We can use the `find_all` function to retrieve all of the list item `<li>` tags. \n",
    "\n",
    "```python\n",
    "soup.find_all('li')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a5a9537-fcc3-47de-8742-92bd5447663a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li class=\"red_text\">Apple</li>, <li>Banana</li>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('li')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105debab-266c-4c44-b305-577e1967d444",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We've successfully extracted all of the `<li>` tags, but our data still isn't very clean. We're not interested in the `HTML` tag, just the data contained within. We can deal with this by using `beautifulsoup` to strip out our HTML tags. \n",
    "\n",
    "```python \n",
    "# We can do this with a loop\n",
    "for tag in soup.find_all('li'):\n",
    "    print(tag.get_text())\n",
    "\n",
    "# Or by using a list comprehension\n",
    "[tag.get_text() for tag in soup.find_all('li')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "234a5484-faf1-4d91-bd13-8642bf36e11d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "Banana\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Apple', 'Banana']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can do this with a loop\n",
    "for tag in soup.find_all('li'):\n",
    "    print(tag.get_text())\n",
    "\n",
    "# Or by using a list comprehension\n",
    "[tag.get_text() for tag in soup.find_all('li')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5994bb6-cde4-4945-a04b-2ec5b7d064fe",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Success, however it will be common that not all the information we want to extract has the same `<tag>` or there will be lots of irrelevant information that has the same `<tag>`. Fortunately, when people are designing web pages they tend to give similar information the same visual appearance. We know that visual appearance is controlled by `css` and using `beautifulsoup` we can extract data by `css` class!\n",
    "\n",
    "```python\n",
    "for red_text in soup.find_all(class_=\"red_text\"):\n",
    "    print(red_text)\n",
    "    \n",
    "[red_text.get_text() for red_text in soup.find_all(class_='red_text')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13894d8a-5b37-44e7-978b-62b177e42f1c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"red_text\">This is my more complex webpage with additional elements</p>\n",
      "<h2 class=\"red_text\">This is an unordered list of fruits</h2>\n",
      "<li class=\"red_text\">Apple</li>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['This is my more complex webpage with additional elements',\n",
       " 'This is an unordered list of fruits',\n",
       " 'Apple']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for red_text in soup.find_all(class_=\"red_text\"):\n",
    "    print(red_text)\n",
    "    \n",
    "[red_text.get_text() for red_text in soup.find_all(class_='red_text')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ac337f-b705-4daf-92ae-9fadfa410ae3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Real world example\n",
    "\n",
    "Lets go back to our wikipedia example, if we remember we were able to use pandas to scrape the table, but weren't able to get all of the country information because this wasn't stored as plain text. We can use `beautifulsoup` to parse out that information with much finer control. \n",
    "\n",
    "First we need to get the `HTML` that generates that wikipedia page. We can do this using our trusty `requests` library. \n",
    "\n",
    "```python \n",
    "import requests\n",
    "\n",
    "URL = 'https://en.wikipedia.org/wiki/Rwanda_men%27s_national_basketball_team'\n",
    "wiki_page = requests.get(URL)\n",
    "print(wiki_page)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d3af6e9-7638-4820-8449-76a84bf68535",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "URL = 'https://en.wikipedia.org/wiki/Rwanda_men%27s_national_basketball_team'\n",
    "wiki_page = requests.get(URL)\n",
    "print(wiki_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9415ee-45ca-4089-a6af-d3c8defa3fed",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Oh, this is just a response code, not the `HTML` that we were expecting. Fortunately `Response [200]` means that the request **successfully** executed. In order to get the `HTML` we need to use the `.text` attribute.\n",
    "\n",
    "```python \n",
    "import requests\n",
    "\n",
    "URL = 'https://en.wikipedia.org/wiki/Rwanda_men%27s_national_basketball_team'\n",
    "wiki_page = requests.get(URL).text\n",
    "print(wiki_page)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07daad9d-cc91-4fd9-8a4b-c1507a8f5f52",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n",
      "<head>\n",
      "<meta charset=\"UTF-8\"/>\n",
      "<title>Rwanda men's national basketball team - Wikipedia</title>\n",
      "<script>document.documentElement.classNam\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "URL = 'https://en.wikipedia.org/wiki/Rwanda_men%27s_national_basketball_team'\n",
    "wiki_page = requests.get(URL).text\n",
    "print(wiki_page[:200]+'\\n...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881a3540-392e-46f7-826a-5c01f922c744",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Now we can parse this `HTML` code with beautiful soup, as we're only interested in the roster table, we can tell `beautifulsoup` to filter out all the `HTML` that isn't related to the roster table. \n",
    "\n",
    "```python\n",
    "tables = soup.find_all('table')\n",
    "print(f'Found {len(tables)} tables.\\n')\n",
    "\n",
    "# Filter list of tables to just those that contain a country \n",
    "# column called Ctr.\n",
    "country_tables = [tbl for tbl in tables if 'Ctr.' in str(tbl)]\n",
    "\n",
    "# This is more complex html than usual, there is a table in a table, so we need to \n",
    "# select the second country_table which represents the inner table.\n",
    "roster_html = country_tables[1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fec010b-c6bd-414d-b8a7-aeb5b12b9d26",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 tables.\n",
      "\n",
      "<table class=\"sortable\" style=\"background:transparent; margin:0px; width:100%;\">\n",
      "<tbody><tr>\n",
      "<th><abbr title=\"Position(s)\">Pos.</abbr></th>\n",
      "<th><abbr title=\"Number\">No.</abbr></th>\n",
      "<th>Name</th>\n",
      "<th>Age – <small>Date of birth</small></th>\n",
      "<th>Height</th>\n",
      "<th>Club</th>\n",
      "<th><abbr title=\"Country\">Ctr.<\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = 'https://en.wikipedia.org/wiki/Rwanda_men%27s_national_basketball_team'\n",
    "wiki_page = requests.get(URL).text\n",
    "soup = BeautifulSoup(wiki_page)\n",
    "\n",
    "tables = soup.find_all('table')\n",
    "print(f'Found {len(tables)} tables.\\n')\n",
    "\n",
    "# Filter list of tables to just those that contain a country \n",
    "# column called Ctr.\n",
    "country_tables = [tbl for tbl in tables if 'Ctr.' in str(tbl)]\n",
    "\n",
    "# This is more complex html than usual, there is a table in a table, so we need to \n",
    "# select the second country_table which represents the inner table.\n",
    "\n",
    "roster_html = country_tables[1]\n",
    "print(str(roster_html)[:300] + '\\n...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eb6507-be4c-47c0-b3d0-5ad6f50c0751",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Try parsing the `roster_html` Beautiful Soup into a `pandas` dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c8aa06-1499-4471-b208-692c0de4d365",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "# Use a list comprehension to look for all the <th> tags, for each \n",
    "# one, get the text and strip the result. These are the column headers\n",
    "# for the table.\n",
    "header = [col.get_text().strip() for col in roster_html.find_all('th')]\n",
    "\n",
    "# Create an empty list to store our processed rows.\n",
    "rows = []\n",
    "# Loop over all of the <tr> tags, each set corresponds to a row\n",
    "# row in our table. \n",
    "for tr in roster_html.find_all('tr')[1:]:\n",
    "    # Create an empty row variable where we can store all of our processed\n",
    "    # data\n",
    "    row = []\n",
    "    # Loop over all of the <td> tags inside the current <tr> tag. These are \n",
    "    # going to be our data items.\n",
    "    for data in tr.find_all('td'):\n",
    "        \n",
    "        # If the data item isn't blank (or just a a new line character)\n",
    "        # then add it to our row, stripping out the excess whitespace\n",
    "        if data.get_text() != '\\n':\n",
    "            row.append(data.get_text().strip())\n",
    "            \n",
    "        # If there is an <img> tag in the <td> tag then we're on our \n",
    "        # flag column. We want to extract the country information. \n",
    "        # We could extract this from the image, but all the images are \n",
    "        # wrapped in a <a> hyperlink tag to that country, which will be\n",
    "        # easier to clean. \n",
    "        if data.find('img') is not None:\n",
    "            # Get the <a> hyperlink tag\n",
    "            img = data.find('a')\n",
    "            # Add the href attribute (this is the link address) to our row\n",
    "            row.append(img['href'])\n",
    "    \n",
    "    # Finally add the row into our list of rows.\n",
    "    rows.append(row)\n",
    "    \n",
    "# Construct a dataframe from our list of rows and our header data\n",
    "df = pd.DataFrame(rows, columns=header)\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8add9f1-4512-45b0-b596-9a97d4a7cb83",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos.</th>\n",
       "      <th>No.</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age – Date of birth</th>\n",
       "      <th>Height</th>\n",
       "      <th>Club</th>\n",
       "      <th>Ctr.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PG</td>\n",
       "      <td>4</td>\n",
       "      <td>Jean Nshobozwabyose</td>\n",
       "      <td>23 – (1998-06-26)26 June 1998</td>\n",
       "      <td>1.83 m (6 ft 0 in)</td>\n",
       "      <td>Patriots</td>\n",
       "      <td>/wiki/Rwanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>5</td>\n",
       "      <td>Ntore Habimana</td>\n",
       "      <td>24 – (1997-08-15)15 August 1997</td>\n",
       "      <td>1.96 m (6 ft 5 in)</td>\n",
       "      <td>Wilfrid Laurier Golden Hawks</td>\n",
       "      <td>/wiki/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SG</td>\n",
       "      <td>6</td>\n",
       "      <td>Steven Hagumintwari</td>\n",
       "      <td>27 – (1993-10-01)1 October 1993</td>\n",
       "      <td>1.93 m (6 ft 4 in)</td>\n",
       "      <td>Patriots</td>\n",
       "      <td>/wiki/Rwanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SG</td>\n",
       "      <td>7</td>\n",
       "      <td>Armel Sangwe</td>\n",
       "      <td>24 – (1997-04-15)15 April 1997</td>\n",
       "      <td>1.90 m (6 ft 3 in)</td>\n",
       "      <td>Espoir</td>\n",
       "      <td>/wiki/Rwanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SG</td>\n",
       "      <td>8</td>\n",
       "      <td>Emile Kazeneza</td>\n",
       "      <td>20 – (2000-08-30)30 August 2000</td>\n",
       "      <td>2.01 m (6 ft 7 in)</td>\n",
       "      <td>William Carey University</td>\n",
       "      <td>/wiki/United_States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SG</td>\n",
       "      <td>9</td>\n",
       "      <td>Dieudonné Ndizeye</td>\n",
       "      <td>24 – (1996-10-14)14 October 1996</td>\n",
       "      <td>1.98 m (6 ft 6 in)</td>\n",
       "      <td>Patriots</td>\n",
       "      <td>/wiki/Rwanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PF</td>\n",
       "      <td>10</td>\n",
       "      <td>Olivier Shyaka</td>\n",
       "      <td>26 – (1995-08-14)14 August 1995</td>\n",
       "      <td>2.00 m (6 ft 7 in)</td>\n",
       "      <td>REG</td>\n",
       "      <td>/wiki/Rwanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "      <td>Alex Mpoyo</td>\n",
       "      <td>24 – (1997-01-05)5 January 1997</td>\n",
       "      <td>2.01 m (6 ft 7 in)</td>\n",
       "      <td>Trepça</td>\n",
       "      <td>/wiki/Kosovo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SG</td>\n",
       "      <td>12</td>\n",
       "      <td>Kenny Gasana</td>\n",
       "      <td>36 – (1984-11-09)9 November 1984</td>\n",
       "      <td>1.90 m (6 ft 3 in)</td>\n",
       "      <td>Patriots</td>\n",
       "      <td>/wiki/Rwanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C</td>\n",
       "      <td>13</td>\n",
       "      <td>Elie Kaje</td>\n",
       "      <td>26 – (1995-03-17)17 March 1995</td>\n",
       "      <td>1.90 m (6 ft 3 in)</td>\n",
       "      <td>Patriots</td>\n",
       "      <td>/wiki/Rwanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C</td>\n",
       "      <td>16</td>\n",
       "      <td>Prince Ibeh</td>\n",
       "      <td>27 – (1994-06-03)3 June 1994</td>\n",
       "      <td>2.06 m (6 ft 9 in)</td>\n",
       "      <td>Patriots</td>\n",
       "      <td>/wiki/Rwanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SF</td>\n",
       "      <td>17</td>\n",
       "      <td>William Robeyns</td>\n",
       "      <td>25 – (1996-02-23)23 February 1996</td>\n",
       "      <td>1.91 m (6 ft 3 in)</td>\n",
       "      <td>Phoenix Brussels</td>\n",
       "      <td>/wiki/Belgium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pos. No.                 Name                Age – Date of birth  \\\n",
       "0    PG   4  Jean Nshobozwabyose      23 – (1998-06-26)26 June 1998   \n",
       "1     G   5       Ntore Habimana    24 – (1997-08-15)15 August 1997   \n",
       "2    SG   6  Steven Hagumintwari    27 – (1993-10-01)1 October 1993   \n",
       "3    SG   7         Armel Sangwe     24 – (1997-04-15)15 April 1997   \n",
       "4    SG   8       Emile Kazeneza    20 – (2000-08-30)30 August 2000   \n",
       "5    SG   9    Dieudonné Ndizeye   24 – (1996-10-14)14 October 1996   \n",
       "6    PF  10       Olivier Shyaka    26 – (1995-08-14)14 August 1995   \n",
       "7     F  11           Alex Mpoyo    24 – (1997-01-05)5 January 1997   \n",
       "8    SG  12         Kenny Gasana   36 – (1984-11-09)9 November 1984   \n",
       "9     C  13            Elie Kaje     26 – (1995-03-17)17 March 1995   \n",
       "10    C  16          Prince Ibeh       27 – (1994-06-03)3 June 1994   \n",
       "11   SF  17      William Robeyns  25 – (1996-02-23)23 February 1996   \n",
       "\n",
       "                Height                          Club                 Ctr.  \n",
       "0   1.83 m (6 ft 0 in)                      Patriots         /wiki/Rwanda  \n",
       "1   1.96 m (6 ft 5 in)  Wilfrid Laurier Golden Hawks         /wiki/Canada  \n",
       "2   1.93 m (6 ft 4 in)                      Patriots         /wiki/Rwanda  \n",
       "3   1.90 m (6 ft 3 in)                        Espoir         /wiki/Rwanda  \n",
       "4   2.01 m (6 ft 7 in)      William Carey University  /wiki/United_States  \n",
       "5   1.98 m (6 ft 6 in)                      Patriots         /wiki/Rwanda  \n",
       "6   2.00 m (6 ft 7 in)                           REG         /wiki/Rwanda  \n",
       "7   2.01 m (6 ft 7 in)                        Trepça         /wiki/Kosovo  \n",
       "8   1.90 m (6 ft 3 in)                      Patriots         /wiki/Rwanda  \n",
       "9   1.90 m (6 ft 3 in)                      Patriots         /wiki/Rwanda  \n",
       "10  2.06 m (6 ft 9 in)                      Patriots         /wiki/Rwanda  \n",
       "11  1.91 m (6 ft 3 in)              Phoenix Brussels        /wiki/Belgium  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a list comprehension to look for all the <th> tags, for each \n",
    "# one, get the text and strip the result. These are the column headers\n",
    "# for the table.\n",
    "header = [col.get_text().strip() for col in roster_html.find_all('th')]\n",
    "\n",
    "# Create an empty list to store our processed rows.\n",
    "rows = []\n",
    "# Loop over all of the <tr> tags, each set corresponds to a row\n",
    "# row in our table. Skip the first row as it contains the <th> tags.\n",
    "for tr in roster_html.find_all('tr')[1:]:\n",
    "    # Create an empty row variable where we can store all of our processed\n",
    "    # data\n",
    "    row = []\n",
    "    # Loop over all of the <td> tags inside the current <tr> tag. These are \n",
    "    # going to be our data items.\n",
    "    for data in tr.find_all('td'):\n",
    "        \n",
    "        # If the data item isn't blank (or just a a new line character)\n",
    "        # then add it to our row, stripping out the excess whitespace\n",
    "        if data.get_text() != '\\n':\n",
    "            row.append(data.get_text().strip())\n",
    "            \n",
    "        # If there is an <img> tag in the <td> tag then we're on our \n",
    "        # flag column. We want to extract the country information. \n",
    "        # We could extract this from the image, but all the images are \n",
    "        # wrapped in a <a> hyperlink tag to that country, which will be\n",
    "        # easier to clean. \n",
    "        if data.find('img') is not None:\n",
    "            # Get the <a> hyperlink tag\n",
    "            img = data.find('a')\n",
    "            # Add the href attribute (this is the link address) to our row\n",
    "            row.append(img['href'])\n",
    "    \n",
    "    # Finally add the row into our list of rows.\n",
    "    rows.append(row)\n",
    "    \n",
    "# Construct a dataframe from our list of rows and our header data\n",
    "df = pd.DataFrame(rows, columns=header)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cee67c-c2a5-4ad9-926c-b4230f3f55d7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Non-tabular data \n",
    "\n",
    "Lets look at less tabular data. This is the [fiba.basketball news page](https://www.fiba.basketball/afrobasket/2021/qualifiers/news). We can see there is list news articles, with headlines, dates and a small blurb. To start lets inspect one of the items and see if we can see anything common that link on. \n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"./imgs/fibanews.png\" width=400></td>\n",
    "        <td><img src=\"./imgs/fibanews_class.png\" width=400></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "All the additional news articles are in `<div>` tags with the class `related_row`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16fccef0-7ecf-4a94-9e57-eb4ac09affb2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"related_row\">\n",
       "<a href=\"http://www.fiba.basketball/afrobasket/2021/qualifiers/news/enabu-rwahwire-reflect-on-uganda-tenacity-ahead-of-morocco-cracker\">\n",
       "<div class=\"related_top right\">\n",
       "<div class=\"date_highlighted\">07/07/2021</div>\n",
       "<div class=\"category\" style=\"background-color: #000000;\">News</div>\n",
       "<h6>Enabu, Rwahwire reflect on Uganda tenacity ahead of Morocco cracker</h6>\n",
       "</div>\n",
       "<div class=\"related_image left adaptive_image\" data-adaptive-image-breakpoints=\"{ default: '/images.fiba.com/Graphic/2/F/7/8/8iqS79S7ukebtkZoyPWr0Q.jpg?v=20210113123220303', 480: '/images.fiba.com/Graphic/F/3/0/5/b8Zt49T0X0CHF0MVS2z46Q.jpg?v=20210113123217152' }\" data-adaptive-image-extra-attrs=\"{ alt: '5 Jimmy Enabu (UGA)' }\">\n",
       "</div>\n",
       "<div class=\"related_bottom right\">\n",
       "<p>SALE (Morocco) - Qualifying for the FIBA AfroBasket is a lifetime dream for many and for Uganda captain Jimmy Enabu, it is a befitting reward to a diligent servant of the game back home. </p>\n",
       "</div>\n",
       "</a>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = 'https://www.fiba.basketball/afrobasket/2021/qualifiers/news'\n",
    "\n",
    "fiba_news = requests.get(URL).text\n",
    "soup = BeautifulSoup(fiba_news)\n",
    "\n",
    "soup.find_all(class_='related_row')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097c25b8-6b5c-40c1-ad18-4f2006a0bbe0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We can see that all the information we want is stored inside this `<div>` tag with the class `related_row`. There is a `<div>` inside with the class `date_highlighted` that contains the date, one with the class `category` that contains the article category information. We can see the title of the article is wrapped in header `<h6>` tags and the blurb of the article is the only `<p>` tag within the `<div>`. \n",
    "\n",
    "Using all this we can write a very simple loop to go through all of the `related_row` objects and pull out the pertinent information using the exact same methods we've already used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f42745d-dd7d-4a74-a53d-560d5edf5f8a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Try parsing the FIBA news page into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "332b96d0-a5bb-4577-b675-c588046d3bd6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>blurb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07/07/2021</td>\n",
       "      <td>Enabu, Rwahwire reflect on Uganda tenacity ahe...</td>\n",
       "      <td>News</td>\n",
       "      <td>SALE (Morocco) - Qualifying for the FIBA AfroB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/03/2021</td>\n",
       "      <td>Madagascar's Botou wants to keep the AfroBaske...</td>\n",
       "      <td>News</td>\n",
       "      <td>ANTANANARIVO (Madagascar) – Despite having mis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/03/2021</td>\n",
       "      <td>10 standout performers from the last window of...</td>\n",
       "      <td>News</td>\n",
       "      <td>ABIDJAN - As we look back at the Second Round ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/03/2021</td>\n",
       "      <td>Guinea celebrate second straight AfroBasket ap...</td>\n",
       "      <td>News</td>\n",
       "      <td>Guinea left Cameroon at the end of the FIBA Af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02/03/2021</td>\n",
       "      <td>Decisions concerning the February window of th...</td>\n",
       "      <td>News</td>\n",
       "      <td>FIBA has taken decisions regarding Equatorial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26/02/2021</td>\n",
       "      <td>Impressive operational efforts in FIBA Contine...</td>\n",
       "      <td>News</td>\n",
       "      <td>MIES (Switzerland) - Another successful window...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24/02/2021</td>\n",
       "      <td>\"Senegal have some room for improvement,\" says...</td>\n",
       "      <td>News</td>\n",
       "      <td>DAKAR (Senegal) - Senegal finished top of Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23/02/2021</td>\n",
       "      <td>History Makers Kenya's confidence is sky-high</td>\n",
       "      <td>News</td>\n",
       "      <td>By beating eleven-time Africa champions Angola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21/02/2021</td>\n",
       "      <td>Four teams undefeated at the end of AfroBasket...</td>\n",
       "      <td>Review</td>\n",
       "      <td>MONASTIR/YAOUNDE (Tunisia/Cameroon) - The 20-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21/02/2021</td>\n",
       "      <td>Top performers at Day 3 in Yaounde</td>\n",
       "      <td>News</td>\n",
       "      <td>YAOUNDE (Cameroon) - There was great frenzy at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21/02/2021</td>\n",
       "      <td>Top performers as curtains fall on FIBA AfroBa...</td>\n",
       "      <td>News</td>\n",
       "      <td>MONASTIR (Tunisia) - With prestige and honor a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21/02/2021</td>\n",
       "      <td>Aristide Mouaha from mop boy to Cameroon inter...</td>\n",
       "      <td>News</td>\n",
       "      <td>YAOUNDE (Cameroon) - The game was in the third...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21/02/2021</td>\n",
       "      <td>Ongwae's buzzer-beater shocks Angola as Kenya ...</td>\n",
       "      <td>Game Report</td>\n",
       "      <td>YAOUNDE (Cameroon) On what was Kenya's biggest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20/02/2021</td>\n",
       "      <td>Three tickets still available for AfroBasket 2021</td>\n",
       "      <td>Review</td>\n",
       "      <td>On the day that Kenya caused the biggest upset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20/02/2021</td>\n",
       "      <td>Romdhane show as Dokossi rises to summit</td>\n",
       "      <td>News</td>\n",
       "      <td>MONASTIR (Tunisia) - Of newbies and veterans e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                           headline  \\\n",
       "0   07/07/2021  Enabu, Rwahwire reflect on Uganda tenacity ahe...   \n",
       "1   11/03/2021  Madagascar's Botou wants to keep the AfroBaske...   \n",
       "2   10/03/2021  10 standout performers from the last window of...   \n",
       "3   08/03/2021  Guinea celebrate second straight AfroBasket ap...   \n",
       "4   02/03/2021  Decisions concerning the February window of th...   \n",
       "5   26/02/2021  Impressive operational efforts in FIBA Contine...   \n",
       "6   24/02/2021  \"Senegal have some room for improvement,\" says...   \n",
       "7   23/02/2021     History Makers Kenya's confidence is sky-high    \n",
       "8   21/02/2021  Four teams undefeated at the end of AfroBasket...   \n",
       "9   21/02/2021                 Top performers at Day 3 in Yaounde   \n",
       "10  21/02/2021  Top performers as curtains fall on FIBA AfroBa...   \n",
       "11  21/02/2021  Aristide Mouaha from mop boy to Cameroon inter...   \n",
       "12  21/02/2021  Ongwae's buzzer-beater shocks Angola as Kenya ...   \n",
       "13  20/02/2021  Three tickets still available for AfroBasket 2021   \n",
       "14  20/02/2021           Romdhane show as Dokossi rises to summit   \n",
       "\n",
       "       category                                              blurb  \n",
       "0          News  SALE (Morocco) - Qualifying for the FIBA AfroB...  \n",
       "1          News  ANTANANARIVO (Madagascar) – Despite having mis...  \n",
       "2          News  ABIDJAN - As we look back at the Second Round ...  \n",
       "3          News  Guinea left Cameroon at the end of the FIBA Af...  \n",
       "4          News  FIBA has taken decisions regarding Equatorial ...  \n",
       "5          News  MIES (Switzerland) - Another successful window...  \n",
       "6          News  DAKAR (Senegal) - Senegal finished top of Grou...  \n",
       "7          News  By beating eleven-time Africa champions Angola...  \n",
       "8        Review  MONASTIR/YAOUNDE (Tunisia/Cameroon) - The 20-t...  \n",
       "9          News  YAOUNDE (Cameroon) - There was great frenzy at...  \n",
       "10         News  MONASTIR (Tunisia) - With prestige and honor a...  \n",
       "11         News  YAOUNDE (Cameroon) - The game was in the third...  \n",
       "12  Game Report  YAOUNDE (Cameroon) On what was Kenya's biggest...  \n",
       "13       Review  On the day that Kenya caused the biggest upset...  \n",
       "14         News  MONASTIR (Tunisia) - Of newbies and veterans e...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set the URL\n",
    "URL = 'https://www.fiba.basketball/afrobasket/2021/qualifiers/news'\n",
    "\n",
    "# Download the webpage\n",
    "fiba_news = requests.get(URL).text\n",
    "# Convert the web page into a beautifulsoup object\n",
    "soup = BeautifulSoup(fiba_news)\n",
    "\n",
    "# Create an empty list to store our extracted information\n",
    "news_items = []\n",
    "\n",
    "# Loop over all the related_row classed divs\n",
    "for news_html in soup.find_all(class_='related_row'):\n",
    "    \n",
    "    # For each related_row class:\n",
    "    # Extract the date using the date_highlighted\n",
    "    date = news_html.find(class_='date_highlighted').get_text()\n",
    "    # Extract the category using the category class \n",
    "    category = news_html.find(class_='category').get_text()\n",
    "    # Extract the headline using the <h6> tag\n",
    "    headline = news_html.find('h6').get_text()\n",
    "    # Extract the blurb using the <p> tags\n",
    "    blurb = news_html.find('p').get_text()\n",
    "    \n",
    "    # Create a dictionary of all the data extracted\n",
    "    data_extracted = dict(date=date, headline=headline, category=category, blurb=blurb)\n",
    "    \n",
    "    # Add the dictionary to the list to store extracted infomration for each article\n",
    "    news_items.append(data_extracted)\n",
    "\n",
    "# Conver the list of dictionarys into a pandas dataframe\n",
    "df = pd.DataFrame(news_items)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d92a660-d65b-4d9d-95df-d25ec3049e92",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Selenium Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c06670-1550-417b-8234-e40c53bc7225",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Lets look at one final example piece of `HTML`. In this one we're going to use some basic `javascript` to add some elements to the page.\n",
    "\n",
    "```html\n",
    "<html>\n",
    "    <head>\n",
    "    <script type='text/javascript'>\n",
    "        window.onload = function(){\n",
    "            for(i=0; i<5; i++){\n",
    "                var paragraph = document.createElement('p');\n",
    "                paragraph.innerHTML = 'This is paragraph '+i;\n",
    "                document.body.appendChild(paragraph);\n",
    "            }\n",
    "        }\n",
    "    </script>\n",
    "    </head>\n",
    "    <body>\n",
    "    </body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dea594-0746-4b35-9b4d-3b05f7972016",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "If we open this `.html` file up in a web browser we get what we'd expect which is 5 paragraph objects labeled 0 to 4. \n",
    "\n",
    "<center><img src=\"./imgs/dynamic_javascript.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef7f0d3-39c7-4b41-b0cf-33de4a31b372",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "But when we try our usual approach of opening this file up into `beautifulsoup` we get the following result. \n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('./dynamic_javascript.html', 'r') as f:\n",
    "    html = f.read()\n",
    "    \n",
    "soup = BeautifulSoup(html)\n",
    "soup.find_all('p')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6838b204-6867-4d4b-924a-a8f6fabce1b6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('./assets/dynamic_javascript.html', 'r') as f:\n",
    "    html = f.read()\n",
    "    \n",
    "soup = BeautifulSoup(html)\n",
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fa5367-95c4-4961-8179-71faae637c5d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "This is because in order for the `<p>` tags to appear on the page there needs to be some process to execute the javascript that generates them. `BeautifulSoup` is just a `HTML` parser, it isn't able to execute javascript that is stored in the `.html` file.\n",
    "\n",
    "This is a difficult problem to deal with, it would be useful if we could access the results of the `.html` file as it is rendered inside our browser, enter Selenium.\n",
    "\n",
    "Selenium is a browser automation tool that is primarily used for testing websites, but can be put to a whole host of different tasks. What the Selenium library allows us to do is control a web browser using python and interact with the results.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b4717-f1b7-40c9-a92e-fc15539f7af0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Installing Selenium \n",
    "\n",
    "Installing Selenium is a little trickier than most python packages, as in additional to a python library, we require a custom version of our web browser that can communicate with the Selenium library. \n",
    "\n",
    "First we can pip install the selenium library \n",
    "```python\n",
    "!pip install selenium\n",
    "```\n",
    "\n",
    "Then we need to go to https://sites.google.com/chromium.org/driver/ and download the latest **stable** release of our chrome driver. Now we need to make sure our selenium library can talk to the web driver, to do this we need to add it to our `system path`; a list of directories our computer looks for programs. \n",
    "\n",
    "1. Create the directory `C:\\bin`\n",
    "2. Extract the chromedriver.exe into `C:\\bin`\n",
    "3. Run the following command \n",
    "\n",
    "```sh\n",
    "setx PATH \"%PATH%;C:\\bin\"\n",
    "```\n",
    "\n",
    "\n",
    "4. Check this worked by restarting the command prompt and running the following\n",
    "\n",
    "```sh\n",
    "chromedriver -v \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dbca79-645b-4235-bdb5-0ba5f397032f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Using Selenium \n",
    "\n",
    "Once Selenium is installed we can import and use it just like any other package, the syntax of selenium is very similar to the packages we've looked at so far. In order to start a Selenium browser session we have to specify the type of browser that we're planning to use. As we installed the Chrome driver we can do this with the following code. \n",
    "\n",
    "```python\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "```\n",
    "\n",
    "You'll notice that running this code opens up a new browser window with the message `Chrome is being controlled by automated test software`. This is the browser that python is going to control. \n",
    "\n",
    "Be careful running this cell multiple times, everytime `webdriver.Chrome()` is called, it will start a new browser but wont close the old one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57106147-d9f5-4784-a05e-9d8543433637",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04747783-8648-4fa8-9ef4-b4a0f1e2d0bc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Now we have a our web driver running, we can tell it to nagivate around to various pages using the `driver.get()`. For example if we wanted to open the Rwanda Men's basketball wikipedia page we would use:\n",
    "\n",
    "```python\n",
    "driver.get('https://en.wikipedia.org/wiki/Rwanda_men%27s_national_basketball_team')\n",
    "```\n",
    "\n",
    "Similarly if we wanted to open our dynamic javascript page, we just need to tell the driver to navigate there. Opening a local file is a little different, first we need to use `file://` rather than `http://` and we also need to enter the full filepath, which we can get from `os.getcwd()`. \n",
    "\n",
    "```python\n",
    "import os \n",
    "\n",
    "local_file = 'file://'+os.getcwd()+'dynamic_javascript.html'\n",
    "driver.get(local_file)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5581f33b-0de4-42e6-9333-caf3cc97094b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "local_file = 'file://' + os.getcwd() + '/assets/dynamic_javascript.html'\n",
    "driver.get(local_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b55b302-d77e-43bf-9bea-f1a3a4e94499",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Once we've navigated our browser to the right page there are several methods we can use to extract data processed HTML. Nearly all methods have a `find_element` and `find_elements` version, returning the first and a list of all the matching elements respectively. \n",
    "\n",
    "| Driver Method | Usage |\n",
    "| --- | --- |\n",
    "| find_element_by_id | Select element by the `id` attribute\n",
    "| find_elements_by_name | Select elements by the `name` attribute |\n",
    "| find_elements_by_xpath | Select elements by an XML path |\n",
    "| find_elements_by_link_text | Select elements with specific hyperlink text |\n",
    "| find_elements_by_partial_link_text | Select elements matching part of hyperlink text |\n",
    "| find_elements_by_tag_name | Select elements by tag name / tag type |\n",
    "| find_elements_by_class_name | Select elements with the same class |\n",
    "| find_elements_by_css_selector | Select elements by CSS selectors | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b979074-e1ee-4c08-a599-14de8d51ee94",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We can use the `find_elements_by_tag_name` method to collect our dynamically generated `<p>` tags. What we get is a list of `WebElement` objects. We can use the `.text` property to retrieve the text inside the tag, or use `.get_attribute('outerHTML')` to extract the full tag as a string\n",
    "\n",
    "```python\n",
    "import os\n",
    "from selenium import webdriver \n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "local_file = 'file://' + os.getcwd() + '/dynamic_javascript.html'\n",
    "\n",
    "driver.get(local_file)\n",
    "p_tags = driver.find_elements_by_tag_name('p')\n",
    "\n",
    "for tag in p_tags:\n",
    "    print(type(tag))\n",
    "    print(tag.get_attribute('outerHTML'))\n",
    "    print(tag.text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0324af49-5473-44d9-8d2a-25fbb560924e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'selenium.webdriver.remote.webelement.WebElement'>\n",
      "<p>This is paragraph 0</p>\n",
      "This is paragraph 0\n",
      "<class 'selenium.webdriver.remote.webelement.WebElement'>\n",
      "<p>This is paragraph 1</p>\n",
      "This is paragraph 1\n",
      "<class 'selenium.webdriver.remote.webelement.WebElement'>\n",
      "<p>This is paragraph 2</p>\n",
      "This is paragraph 2\n",
      "<class 'selenium.webdriver.remote.webelement.WebElement'>\n",
      "<p>This is paragraph 3</p>\n",
      "This is paragraph 3\n",
      "<class 'selenium.webdriver.remote.webelement.WebElement'>\n",
      "<p>This is paragraph 4</p>\n",
      "This is paragraph 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver \n",
    "\n",
    "# driver = webdriver.Chrome()\n",
    "local_file = 'file://' + os.getcwd() + '/assets/dynamic_javascript.html'\n",
    "\n",
    "driver.get(local_file)\n",
    "p_tags = driver.find_elements_by_tag_name('p')\n",
    "\n",
    "for tag in p_tags:\n",
    "    print(type(tag))\n",
    "    print(tag.get_attribute('outerHTML'))\n",
    "    print(tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7138098-ad58-4a26-9f44-82bcbf8eba08",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "In some cases it may be more useful to use Selenium to generate the page, but then parse the resulting HTML using BeautifulSoup. Fortunately Selenium allows us to access the full HTML of the page including all of the generated elements. \n",
    "\n",
    "```python \n",
    "import os \n",
    "from selenium import webdriver \n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "local_file = 'file://' + os.getcwd() + 'dynamic_javascript.html'\n",
    "\n",
    "driver.get(local_file)\n",
    "driver.get(local_file)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "soup.find_all('p')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf3b1964-6abe-48eb-a4c5-08057336b3aa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>This is paragraph 0</p>,\n",
       " <p>This is paragraph 1</p>,\n",
       " <p>This is paragraph 2</p>,\n",
       " <p>This is paragraph 3</p>,\n",
       " <p>This is paragraph 4</p>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver \n",
    "\n",
    "# driver = webdriver.Chrome()\n",
    "local_file = 'file://' + os.getcwd() + '/assets/dynamic_javascript.html'\n",
    "\n",
    "driver.get(local_file)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302958fb-2587-4553-a8e7-1cb8e2b2d150",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Practical Example \n",
    "\n",
    "Lets look at the [fiba.basketball news page](https://www.fiba.basketball/afrobasket/2021/qualifiers/news). If we go to the bottom of the page we can see there is a button that says `Show More News`. This button dynamically loads more news onto the page we're currently viewing. \n",
    "\n",
    "We wouldn't be able to get this using `requests` alone, but maybe selenium can help. First we need to tell selenium that we want to click that button, but before we can click it we need to find it. \n",
    "\n",
    "<center><img src=\"./imgs/fiba_showmore.png\" width=500></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a998f793-7117-4c82-933a-7760a9234b7a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Using the `Inspect` tool we can see that the button has the class `show_more_button` so we can use that and a selenium class selector to isolate the element.\n",
    "\n",
    "Once we've done that we can use the built in `click` method for `WebElements` to simulate us clicking the the `Show More News` button. \n",
    "\n",
    "```python \n",
    "from selenium import webdriver \n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "URL = 'https://www.fiba.basketball/afrobasket/2021/qualifiers/news'\n",
    "driver.get(URL)\n",
    "\n",
    "button = driver.find_element_by_class_name('show_more_button')\n",
    "button.click()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e83db90b-4b72-4044-bc4b-2abcc6c00853",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "URL = 'https://www.fiba.basketball/afrobasket/2021/qualifiers/news'\n",
    "driver.get(URL)\n",
    "\n",
    "button = driver.find_element_by_class_name('show_more_button')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52de4f4-48ef-47bd-a1bd-e940a1a152da",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Now if we use the same code we used previously to scrape this information, swapping out the request's call for the Selenium one, we can \n",
    "parse even more news than we did previously. \n",
    "\n",
    "Note, clicking on the button doesn't generate the new news items instantly, it takes a moment for the browser to collect them. We need to add a wait function using `time.sleep` to wait for the page to load before we can scrape the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3b5d2d4-9f36-46b5-9154-2e9b5142126f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>blurb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07/07/2021</td>\n",
       "      <td>Enabu, Rwahwire reflect on Uganda tenacity ahe...</td>\n",
       "      <td>News</td>\n",
       "      <td>SALE (Morocco) - Qualifying for the FIBA AfroB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/03/2021</td>\n",
       "      <td>Madagascar's Botou wants to keep the AfroBaske...</td>\n",
       "      <td>News</td>\n",
       "      <td>ANTANANARIVO (Madagascar) – Despite having mis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/03/2021</td>\n",
       "      <td>10 standout performers from the last window of...</td>\n",
       "      <td>News</td>\n",
       "      <td>ABIDJAN - As we look back at the Second Round ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/03/2021</td>\n",
       "      <td>Guinea celebrate second straight AfroBasket ap...</td>\n",
       "      <td>News</td>\n",
       "      <td>Guinea left Cameroon at the end of the FIBA Af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02/03/2021</td>\n",
       "      <td>Decisions concerning the February window of th...</td>\n",
       "      <td>News</td>\n",
       "      <td>FIBA has taken decisions regarding Equatorial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26/02/2021</td>\n",
       "      <td>Impressive operational efforts in FIBA Contine...</td>\n",
       "      <td>News</td>\n",
       "      <td>MIES (Switzerland) - Another successful window...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24/02/2021</td>\n",
       "      <td>\"Senegal have some room for improvement,\" says...</td>\n",
       "      <td>News</td>\n",
       "      <td>DAKAR (Senegal) - Senegal finished top of Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23/02/2021</td>\n",
       "      <td>History Makers Kenya's confidence is sky-high</td>\n",
       "      <td>News</td>\n",
       "      <td>By beating eleven-time Africa champions Angola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21/02/2021</td>\n",
       "      <td>Four teams undefeated at the end of AfroBasket...</td>\n",
       "      <td>Review</td>\n",
       "      <td>MONASTIR/YAOUNDE (Tunisia/Cameroon) - The 20-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21/02/2021</td>\n",
       "      <td>Top performers at Day 3 in Yaounde</td>\n",
       "      <td>News</td>\n",
       "      <td>YAOUNDE (Cameroon) - There was great frenzy at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21/02/2021</td>\n",
       "      <td>Top performers as curtains fall on FIBA AfroBa...</td>\n",
       "      <td>News</td>\n",
       "      <td>MONASTIR (Tunisia) - With prestige and honor a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21/02/2021</td>\n",
       "      <td>Aristide Mouaha from mop boy to Cameroon inter...</td>\n",
       "      <td>News</td>\n",
       "      <td>YAOUNDE (Cameroon) - The game was in the third...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21/02/2021</td>\n",
       "      <td>Ongwae's buzzer-beater shocks Angola as Kenya ...</td>\n",
       "      <td>Game Report</td>\n",
       "      <td>YAOUNDE (Cameroon) On what was Kenya's biggest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20/02/2021</td>\n",
       "      <td>Three tickets still available for AfroBasket 2021</td>\n",
       "      <td>Review</td>\n",
       "      <td>On the day that Kenya caused the biggest upset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20/02/2021</td>\n",
       "      <td>Romdhane show as Dokossi rises to summit</td>\n",
       "      <td>News</td>\n",
       "      <td>MONASTIR (Tunisia) - Of newbies and veterans e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20/02/2021</td>\n",
       "      <td>Ongwae, Ndoye, Nzeulie and Obiekwe dazzle in Y...</td>\n",
       "      <td>News</td>\n",
       "      <td>Magical and electrifying may not come close to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20/02/2021</td>\n",
       "      <td>Liz Mills trailblazing for more female coaches...</td>\n",
       "      <td>News</td>\n",
       "      <td>YAOUNDE (Cameroon) - A dream nursed in Sydney,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20/02/2021</td>\n",
       "      <td>Iroegbu brothers excited to continue Nigerian ...</td>\n",
       "      <td>Long Read</td>\n",
       "      <td>MONASTIR (Tunisia) - Playing with your sibling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20/02/2021</td>\n",
       "      <td>Cote d'Ivoire's Konate defying age in style</td>\n",
       "      <td>News</td>\n",
       "      <td>YAOUNDE (Cameroon) - Cote d'Ivoire's Stephane ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20/02/2021</td>\n",
       "      <td>Kouguere magic as Central African Republic edg...</td>\n",
       "      <td>Game Report</td>\n",
       "      <td>MONASTIR (Tunisia) - Central African Republic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19/02/2021</td>\n",
       "      <td>Nshobozwabyosenumukiza, Diogu sign out on a high</td>\n",
       "      <td>News</td>\n",
       "      <td>MONASTIR (Tunisia) - Rwanda point guard Jean J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>19/02/2021</td>\n",
       "      <td>Morais, Diallo, Mansare and Thompson star in Y...</td>\n",
       "      <td>News</td>\n",
       "      <td>YAOUNDE (Cameroon) - There was fireworks at th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>19/02/2021</td>\n",
       "      <td>Rwanda pick first win as four more teams quali...</td>\n",
       "      <td>Review</td>\n",
       "      <td>MONASTIR/YAOUNDE (Tunisia/Cameroon) - Rwanda p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>19/02/2021</td>\n",
       "      <td>Angola's Leonel Paulo bringing his experience ...</td>\n",
       "      <td>News</td>\n",
       "      <td>YAOUNDE (Cameroon) - When you've played at fiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19/02/2021</td>\n",
       "      <td>FIBA Statement about the February FIBA AfroBas...</td>\n",
       "      <td>Statement</td>\n",
       "      <td>Following the Covid-19 Protocol for FIBA Offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>19/02/2021</td>\n",
       "      <td>Luol Deng's South Sudan revel in FIBA AfroBask...</td>\n",
       "      <td>News</td>\n",
       "      <td>MONASTIR (Tunisia) - It has been a long journe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19/02/2021</td>\n",
       "      <td>Senegal's Ndoye \"We want to stay unbeaten\"</td>\n",
       "      <td>News</td>\n",
       "      <td>YAOUNDE (Cameroon) - Whenever five-time Afroba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18/02/2021</td>\n",
       "      <td>Kuany, Doucoure and Omoerah in cloud nine at F...</td>\n",
       "      <td>News</td>\n",
       "      <td>MONASTIR (Tunisia) - Kuany Ngor Kuany was at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>18/02/2021</td>\n",
       "      <td>South Sudan, Mali qualify for AfroBasket 2021,...</td>\n",
       "      <td>Review</td>\n",
       "      <td>Day 2 of February's window of the FIBA AfroBas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>18/02/2021</td>\n",
       "      <td>Players to watch out for in FIBA AfroBasket 20...</td>\n",
       "      <td>News</td>\n",
       "      <td>YAOUNDE (Cameroon) - The third and final windo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                           headline  \\\n",
       "0   07/07/2021  Enabu, Rwahwire reflect on Uganda tenacity ahe...   \n",
       "1   11/03/2021  Madagascar's Botou wants to keep the AfroBaske...   \n",
       "2   10/03/2021  10 standout performers from the last window of...   \n",
       "3   08/03/2021  Guinea celebrate second straight AfroBasket ap...   \n",
       "4   02/03/2021  Decisions concerning the February window of th...   \n",
       "5   26/02/2021  Impressive operational efforts in FIBA Contine...   \n",
       "6   24/02/2021  \"Senegal have some room for improvement,\" says...   \n",
       "7   23/02/2021     History Makers Kenya's confidence is sky-high    \n",
       "8   21/02/2021  Four teams undefeated at the end of AfroBasket...   \n",
       "9   21/02/2021                 Top performers at Day 3 in Yaounde   \n",
       "10  21/02/2021  Top performers as curtains fall on FIBA AfroBa...   \n",
       "11  21/02/2021  Aristide Mouaha from mop boy to Cameroon inter...   \n",
       "12  21/02/2021  Ongwae's buzzer-beater shocks Angola as Kenya ...   \n",
       "13  20/02/2021  Three tickets still available for AfroBasket 2021   \n",
       "14  20/02/2021           Romdhane show as Dokossi rises to summit   \n",
       "15  20/02/2021  Ongwae, Ndoye, Nzeulie and Obiekwe dazzle in Y...   \n",
       "16  20/02/2021  Liz Mills trailblazing for more female coaches...   \n",
       "17  20/02/2021  Iroegbu brothers excited to continue Nigerian ...   \n",
       "18  20/02/2021        Cote d'Ivoire's Konate defying age in style   \n",
       "19  20/02/2021  Kouguere magic as Central African Republic edg...   \n",
       "20  19/02/2021   Nshobozwabyosenumukiza, Diogu sign out on a high   \n",
       "21  19/02/2021  Morais, Diallo, Mansare and Thompson star in Y...   \n",
       "22  19/02/2021  Rwanda pick first win as four more teams quali...   \n",
       "23  19/02/2021  Angola's Leonel Paulo bringing his experience ...   \n",
       "24  19/02/2021  FIBA Statement about the February FIBA AfroBas...   \n",
       "25  19/02/2021  Luol Deng's South Sudan revel in FIBA AfroBask...   \n",
       "26  19/02/2021         Senegal's Ndoye \"We want to stay unbeaten\"   \n",
       "27  18/02/2021  Kuany, Doucoure and Omoerah in cloud nine at F...   \n",
       "28  18/02/2021  South Sudan, Mali qualify for AfroBasket 2021,...   \n",
       "29  18/02/2021  Players to watch out for in FIBA AfroBasket 20...   \n",
       "\n",
       "       category                                              blurb  \n",
       "0          News  SALE (Morocco) - Qualifying for the FIBA AfroB...  \n",
       "1          News  ANTANANARIVO (Madagascar) – Despite having mis...  \n",
       "2          News  ABIDJAN - As we look back at the Second Round ...  \n",
       "3          News  Guinea left Cameroon at the end of the FIBA Af...  \n",
       "4          News  FIBA has taken decisions regarding Equatorial ...  \n",
       "5          News  MIES (Switzerland) - Another successful window...  \n",
       "6          News  DAKAR (Senegal) - Senegal finished top of Grou...  \n",
       "7          News  By beating eleven-time Africa champions Angola...  \n",
       "8        Review  MONASTIR/YAOUNDE (Tunisia/Cameroon) - The 20-t...  \n",
       "9          News  YAOUNDE (Cameroon) - There was great frenzy at...  \n",
       "10         News  MONASTIR (Tunisia) - With prestige and honor a...  \n",
       "11         News  YAOUNDE (Cameroon) - The game was in the third...  \n",
       "12  Game Report  YAOUNDE (Cameroon) On what was Kenya's biggest...  \n",
       "13       Review  On the day that Kenya caused the biggest upset...  \n",
       "14         News  MONASTIR (Tunisia) - Of newbies and veterans e...  \n",
       "15         News  Magical and electrifying may not come close to...  \n",
       "16         News  YAOUNDE (Cameroon) - A dream nursed in Sydney,...  \n",
       "17    Long Read  MONASTIR (Tunisia) - Playing with your sibling...  \n",
       "18         News  YAOUNDE (Cameroon) - Cote d'Ivoire's Stephane ...  \n",
       "19  Game Report  MONASTIR (Tunisia) - Central African Republic ...  \n",
       "20         News  MONASTIR (Tunisia) - Rwanda point guard Jean J...  \n",
       "21         News  YAOUNDE (Cameroon) - There was fireworks at th...  \n",
       "22       Review  MONASTIR/YAOUNDE (Tunisia/Cameroon) - Rwanda p...  \n",
       "23         News  YAOUNDE (Cameroon) - When you've played at fiv...  \n",
       "24    Statement  Following the Covid-19 Protocol for FIBA Offic...  \n",
       "25         News  MONASTIR (Tunisia) - It has been a long journe...  \n",
       "26         News  YAOUNDE (Cameroon) - Whenever five-time Afroba...  \n",
       "27         News  MONASTIR (Tunisia) - Kuany Ngor Kuany was at t...  \n",
       "28       Review  Day 2 of February's window of the FIBA AfroBas...  \n",
       "29         News  YAOUNDE (Cameroon) - The third and final windo...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Set the URL\n",
    "URL = 'https://www.fiba.basketball/afrobasket/2021/qualifiers/news'\n",
    "\n",
    "# Navigate our page to the URL \n",
    "driver.get(URL)\n",
    "\n",
    "# Find the show_more_button and click it \n",
    "button = driver.find_element_by_class_name('show_more_button')\n",
    "button.click()\n",
    "\n",
    "# We need to add a wait function here, otherwise the page wont have \n",
    "# loaded the new elements before it attempts to parse them. \n",
    "time.sleep(10)\n",
    "\n",
    "# Download the webpage\n",
    "fiba_news = driver.page_source\n",
    "# Convert the web page into a beautifulsoup object\n",
    "soup = BeautifulSoup(fiba_news)\n",
    "\n",
    "# Create an empty list to store our extracted information\n",
    "news_items = []\n",
    "\n",
    "# Loop over all the related_row classed divs\n",
    "for news_html in soup.find_all(class_='related_row'):\n",
    "    \n",
    "    # For each related_row class:\n",
    "    # Extract the date using the date_highlighted\n",
    "    date = news_html.find(class_='date_highlighted').get_text()\n",
    "    # Extract the category using the category class \n",
    "    category = news_html.find(class_='category').get_text()\n",
    "    # Extract the headline using the <h6> tag\n",
    "    headline = news_html.find('h6').get_text()\n",
    "    # Extract the blurb using the <p> tags\n",
    "    blurb = news_html.find('p').get_text()\n",
    "    \n",
    "    # Create a dictionary of all the data extracted\n",
    "    data_extracted = dict(date=date, headline=headline, category=category, blurb=blurb)\n",
    "    \n",
    "    # Add the dictionary to the list to store extracted infomration for each article\n",
    "    news_items.append(data_extracted)\n",
    "\n",
    "# Conver the list of dictionarys into a pandas dataframe\n",
    "df = pd.DataFrame(news_items)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
